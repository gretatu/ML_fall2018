{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this application is to solve relevant classification and regression problems for the prostate dataset for use in the project in 02450 Intro to Machine Learning\n",
    "\n",
    "Author: Naia Wright\n",
    "\n",
    "Reviewed by:  \n",
    "\n",
    "Last modified: 28/10/18, 09:39\n",
    "\n",
    "#### Change-log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "\n",
    "from matplotlib.pyplot import figure, boxplot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection, tree\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, xlabel, ylabel, show, clim\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a method for importing a spread_sheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, sheet):\n",
    "    \"\"\"\n",
    "    Method for importing data from a spreadsheet.\n",
    "\n",
    "    :param path: full path to the spreadsheet to load\n",
    "    :param sheet: name of the sheet in the workbook that is loaded\n",
    "    :return: pandas dataFrame with imported data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    out = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path and sheet name in the prostate workbook\n",
    "#filePath = 'C:/Users/PeterBakke/Documents/git/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/Greta/Documents/Github/ML_fall2018/Data/Prostate.xlsx'\n",
    "filePath = 'C:/Users/narisa/Documents/GitHub/ML_fall2018/Data/Prostate.xlsx'\n",
    "sheet = 'Sheet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prostate data into dataFrame\n",
    "myData = DataLoader(path=filePath, sheet=sheet)\n",
    "\n",
    "# delete irrelevant columns\n",
    "del myData['ID']\n",
    "del myData['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol', 'lWeight', 'Age', 'lBPH', 'SVI', 'lCP', 'Gleason', 'pgg45', 'lPSA']\n",
      "{6: 0, 7: 1, 8: 2, 9: 3}\n"
     ]
    }
   ],
   "source": [
    "# extract class names and encode with integers (dict)\n",
    "\n",
    "classLabels = myData['Gleason'].values.tolist()\n",
    "classNames = sorted(set(classLabels))\n",
    "classDict = dict(zip(classNames, range(4)))\n",
    "\n",
    "#del myData['Gleason']\n",
    "\n",
    "attributeNames = list(myData.columns.values)\n",
    "\n",
    "print(attributeNames)\n",
    "print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector y, convert to NumPy array\n",
    "y = np.asarray([classDict[value] for value in classLabels])\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "X = myData.values\n",
    "\n",
    "# Compute values of N, M and C\n",
    "N = len(y)\n",
    "M = len(attributeNames)\n",
    "C = len(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with mean and std\n",
    "Y = (X - np.ones((N,1))*X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.79818495e-01  2.76945900e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -4.30782900e-01]\n",
      " [-9.94252273e-01  3.31962600e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [-5.10825624e-01  2.69124300e+00  7.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "  -1.62518900e-01]\n",
      " [-1.20397280e+00  3.28278900e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [ 7.51416089e-01  3.43237300e+00  6.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.71563600e-01]\n",
      " [-1.04982212e+00  3.22882600e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 7.37164066e-01  3.47351800e+00  6.40000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 6.93147181e-01  3.53950900e+00  5.80000000e+01  1.53686722e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   8.54415300e-01]\n",
      " [-7.76528789e-01  3.53950900e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.23143551e-01  3.24454400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.54642218e-01  3.60413800e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [-1.34707365e+00  3.59868100e+00  6.30000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [ 1.61342993e+00  3.02286100e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.26694760e+00]\n",
      " [ 1.47704872e+00  2.99822900e+00  6.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   1.34807310e+00]\n",
      " [ 1.20597081e+00  3.44201900e+00  5.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  5.00000000e+00\n",
      "   1.39871690e+00]\n",
      " [ 1.54115907e+00  3.06105200e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.44691900e+00]\n",
      " [-4.15515444e-01  3.51601300e+00  7.00000000e+01  1.24415459e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.47017580e+00]\n",
      " [ 2.28848617e+00  3.64935900e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.49290410e+00]\n",
      " [-5.62118918e-01  3.26766600e+00  4.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.55814460e+00]\n",
      " [ 1.82321557e-01  3.82537500e+00  7.00000000e+01  1.65822808e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.59938760e+00]\n",
      " [ 1.14740245e+00  3.41936500e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.63899670e+00]\n",
      " [ 2.05923883e+00  3.50104300e+00  6.00000000e+01  1.47476301e+00\n",
      "   0.00000000e+00  1.34807315e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.65822810e+00]\n",
      " [-5.44727175e-01  3.37588000e+00  5.90000000e+01 -7.98507700e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.69561560e+00]\n",
      " [ 1.78170913e+00  3.45157400e+00  6.30000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  1.17865500e+00  7.00000000e+00  6.00000000e+01\n",
      "   1.71379790e+00]\n",
      " [ 3.85262401e-01  3.66740000e+00  6.90000000e+01  1.59938758e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.73165550e+00]\n",
      " [ 1.44691898e+00  3.12456500e+00  6.80000000e+01  3.00104590e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.76644170e+00]\n",
      " [ 5.12823626e-01  3.71965100e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  7.00000000e+01\n",
      "   1.80005830e+00]\n",
      " [-4.00477567e-01  3.86597900e+00  6.70000000e+01  1.81645208e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.81645210e+00]\n",
      " [ 1.04027671e+00  3.12895100e+00  6.70000000e+01  2.23143550e-01\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  8.00000000e+01\n",
      "   1.84845480e+00]\n",
      " [ 2.40964417e+00  3.37588000e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.61938824e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.89461690e+00]\n",
      " [ 2.85178942e-01  4.09016900e+00  6.50000000e+01  1.96290773e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.92424870e+00]\n",
      " [ 1.82321557e-01  3.80443800e+00  6.50000000e+01  1.70474809e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 1.27536280e+00  3.03735400e+00  7.10000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 9.95033100e-03  3.26766600e+00  5.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.02154760e+00]\n",
      " [-1.00503360e-02  3.21687400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.04769280e+00]\n",
      " [ 1.30833282e+00  4.11985000e+00  6.40000000e+01  2.17133681e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.08567210e+00]\n",
      " [ 1.42310833e+00  3.65713100e+00  7.30000000e+01 -5.79818500e-01\n",
      "   0.00000000e+00  1.65822808e+00  8.00000000e+00  1.50000000e+01\n",
      "   2.15755930e+00]\n",
      " [ 4.57424847e-01  2.37490600e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.19165350e+00]\n",
      " [ 2.66095859e+00  4.08513600e+00  6.80000000e+01  1.37371558e+00\n",
      "   1.00000000e+00  1.83258146e+00  7.00000000e+00  3.50000000e+01\n",
      "   2.21375390e+00]\n",
      " [ 7.97507196e-01  3.01308100e+00  5.60000000e+01  9.36093360e-01\n",
      "   0.00000000e+00 -1.62518930e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.27726730e+00]\n",
      " [ 6.20576488e-01  3.14199500e+00  6.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  9.00000000e+00  8.00000000e+01\n",
      "   2.29757260e+00]\n",
      " [ 1.44220199e+00  3.68261000e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   2.30757260e+00]\n",
      " [ 5.82215620e-01  3.86597900e+00  6.20000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.32727770e+00]\n",
      " [ 1.77155676e+00  3.89690900e+00  6.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  6.00000000e+00\n",
      "   2.37490580e+00]\n",
      " [ 1.48613970e+00  3.40949600e+00  6.60000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.52172060e+00]\n",
      " [ 1.66392610e+00  3.39282900e+00  6.10000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.55334380e+00]\n",
      " [ 2.72785283e+00  3.99544500e+00  7.90000000e+01  1.87946505e+00\n",
      "   1.00000000e+00  2.65675691e+00  9.00000000e+00  1.00000000e+02\n",
      "   2.56878810e+00]\n",
      " [ 1.16315081e+00  4.03512500e+00  6.80000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  4.00000000e+01\n",
      "   2.56878810e+00]\n",
      " [ 1.74571553e+00  3.49802200e+00  4.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.22082992e+00  3.56812300e+00  7.00000000e+01  1.37371558e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.09192330e+00  3.99360300e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+01\n",
      "   2.65675690e+00]\n",
      " [ 1.66013103e+00  4.23483100e+00  6.40000000e+01  2.07317193e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.67759100e+00]\n",
      " [ 5.12823626e-01  3.63363100e+00  6.40000000e+01  1.49290410e+00\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  7.00000000e+01\n",
      "   2.68444030e+00]\n",
      " [ 2.12704052e+00  4.12147300e+00  6.80000000e+01  1.76644166e+00\n",
      "   0.00000000e+00  1.44691898e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.69124310e+00]\n",
      " [ 3.15359036e+00  3.51601300e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.70471130e+00]\n",
      " [ 1.26694760e+00  4.28013200e+00  6.60000000e+01  2.12226154e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.71800050e+00]\n",
      " [ 9.74559640e-01  2.86505400e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  4.00000000e+00\n",
      "   2.78809290e+00]\n",
      " [ 4.63734016e-01  3.76468200e+00  4.90000000e+01  1.42310833e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.79422790e+00]\n",
      " [ 5.42324291e-01  4.17822600e+00  7.00000000e+01  4.38254930e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   2.80638610e+00]\n",
      " [ 1.06125650e+00  3.85121100e+00  6.10000000e+01  1.29472717e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.81241020e+00]\n",
      " [ 4.57424847e-01  4.52450200e+00  7.30000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.84199820e+00]\n",
      " [ 1.99741771e+00  3.71965100e+00  6.30000000e+01  1.61938824e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.77570885e+00  3.52488900e+00  7.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.55814462e+00  9.00000000e+00  9.50000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.03470565e+00  3.91701100e+00  6.60000000e+01  2.00821403e+00\n",
      "   1.00000000e+00  2.11021320e+00  7.00000000e+00  6.00000000e+01\n",
      "   2.88200350e+00]\n",
      " [ 2.07317193e+00  3.62300700e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.88200350e+00]\n",
      " [ 1.45861502e+00  3.83622100e+00  6.10000000e+01  1.32175584e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.88759010e+00]\n",
      " [ 2.02287119e+00  3.87846600e+00  6.80000000e+01  1.78339122e+00\n",
      "   0.00000000e+00  1.32175584e+00  7.00000000e+00  7.00000000e+01\n",
      "   2.92046980e+00]\n",
      " [ 2.19833507e+00  4.05091500e+00  7.20000000e+01  2.30757263e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  1.00000000e+01\n",
      "   2.96269240e+00]\n",
      " [-4.46287103e-01  4.40854700e+00  6.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.96269240e+00]\n",
      " [ 1.19392247e+00  4.78038300e+00  7.20000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.97297530e+00]\n",
      " [ 1.86408013e+00  3.59319400e+00  6.00000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.01308090e+00]\n",
      " [ 1.16002092e+00  3.34109300e+00  7.70000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.50000000e+01\n",
      "   3.03735390e+00]\n",
      " [ 1.21491274e+00  3.82537500e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.23143550e-01  7.00000000e+00  2.00000000e+01\n",
      "   3.05635690e+00]\n",
      " [ 1.83896107e+00  3.23671600e+00  6.00000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  1.17865500e+00  9.00000000e+00  9.00000000e+01\n",
      "   3.07500550e+00]\n",
      " [ 2.99922616e+00  3.84908300e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  2.00000000e+01\n",
      "   3.27525620e+00]\n",
      " [ 3.14113048e+00  3.26384900e+00  6.80000000e+01 -5.12932900e-02\n",
      "   1.00000000e+00  2.42036813e+00  7.00000000e+00  5.00000000e+01\n",
      "   3.33754740e+00]\n",
      " [ 2.01089500e+00  4.43378900e+00  7.20000000e+01  2.12226154e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  6.00000000e+01\n",
      "   3.39282910e+00]\n",
      " [ 2.53765721e+00  4.35478400e+00  7.80000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   3.43559880e+00]\n",
      " [ 2.64830020e+00  3.58212900e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.58399755e+00  7.00000000e+00  7.00000000e+01\n",
      "   3.45789270e+00]\n",
      " [ 2.77944020e+00  3.82319200e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  7.00000000e+00  5.00000000e+01\n",
      "   3.51303690e+00]\n",
      " [ 1.46787435e+00  3.07037600e+00  6.60000000e+01  5.59615790e-01\n",
      "   0.00000000e+00  2.23143550e-01  7.00000000e+00  4.00000000e+01\n",
      "   3.51601310e+00]\n",
      " [ 2.51365606e+00  3.47351800e+00  5.70000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.53076260e+00]\n",
      " [ 2.61300665e+00  3.88875400e+00  7.70000000e+01 -5.27632740e-01\n",
      "   1.00000000e+00  5.59615790e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.56529840e+00]\n",
      " [ 2.67759099e+00  3.83837600e+00  6.50000000e+01  1.11514159e+00\n",
      "   0.00000000e+00  1.74919985e+00  9.00000000e+00  7.00000000e+01\n",
      "   3.57094020e+00]\n",
      " [ 1.56234630e+00  3.70990700e+00  6.00000000e+01  1.69561561e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.58767690e+00]\n",
      " [ 3.30284926e+00  3.51898000e+00  6.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.63098550e+00]\n",
      " [ 2.02419307e+00  3.73169900e+00  5.80000000e+01  1.63899671e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.68009090e+00]\n",
      " [ 1.73165554e+00  3.36901800e+00  6.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  3.00104590e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.71235180e+00]\n",
      " [ 2.80759383e+00  4.71805200e+00  6.50000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.98434370e+00]\n",
      " [ 1.56234630e+00  3.69511000e+00  7.60000000e+01  9.36093360e-01\n",
      "   1.00000000e+00  8.10930220e-01  7.00000000e+00  7.50000000e+01\n",
      "   3.99360300e+00]\n",
      " [ 3.24649099e+00  4.10181700e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   4.02980600e+00]\n",
      " [ 2.53290285e+00  3.67756600e+00  6.10000000e+01  1.34807315e+00\n",
      "   1.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   4.12955080e+00]\n",
      " [ 2.83026783e+00  3.87639600e+00  6.80000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   4.38514680e+00]\n",
      " [ 3.82100361e+00  3.89690900e+00  4.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.16905370e+00  7.00000000e+00  4.00000000e+01\n",
      "   4.68444340e+00]\n",
      " [ 2.90744736e+00  3.39618500e+00  5.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  1.00000000e+01\n",
      "   5.14312450e+00]\n",
      " [ 2.88256357e+00  3.77391000e+00  6.80000000e+01  1.55814462e+00\n",
      "   1.00000000e+00  1.55814462e+00  7.00000000e+00  8.00000000e+01\n",
      "   5.47750900e+00]\n",
      " [ 3.47196645e+00  3.97499800e+00  6.80000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  2.90416508e+00  7.00000000e+00  2.00000000e+01\n",
      "   5.58293220e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Remove attribute 5 (SVI) from X\n",
    "X_classification = X[:,[0,1,2,3,5,6,7,8]]\n",
    "print(X)\n",
    "# Use attribute 5 (SVI) as y\n",
    "y_classification = X[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_est_white_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-64703e7f17cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mclass0_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass0_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est_white_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass0_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mclass1_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass1_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est_white_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass1_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_est_white_prob' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f1cbc11630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = lm.logistic.LogisticRegression()\n",
    "model = model.fit(X_classification,y_classification)\n",
    "\n",
    "# Classify observation according to SVI (0/1) and assess probabilities\n",
    "y_est = model.predict(X_classification)\n",
    "y_est_no_SVI_prob = model.predict_proba(X_classification)[:, 0] \n",
    "\n",
    "# Define a new data object (new type of wine), as in exercise 5.1.7\n",
    "#x = np.array([6.9, 1.09, .06, 2.1, .0061, 12, 31, .99, 3.5, .44, 12]).reshape(1,-1)\n",
    "# Evaluate the probability of x being a white wine (class=0) \n",
    "#x_class = model.predict_proba(x)[0,0]\n",
    "\n",
    "# Evaluate classifier's misclassification rate over entire training data\n",
    "misclass_rate = sum(np.abs(y_est - y_classification)) / float(len(y_est))\n",
    "\n",
    "# Display classification results\n",
    "#print('\\nProbability of given sample not having a white wine: {0:.4f}'.format(x_class))\n",
    "#print('\\nOverall misclassification rate: {0:.3f}'.format(misclass_rate))\n",
    "\n",
    "f = figure();\n",
    "class0_ids = np.nonzero(y==0)[0].tolist()\n",
    "plot(class0_ids, y_est_white_prob[class0_ids], '.y')\n",
    "class1_ids = np.nonzero(y==1)[0].tolist()\n",
    "plot(class1_ids, y_est_white_prob[class1_ids], '.r')\n",
    "xlabel('Data object (men)'); ylabel('Predicted prob. of no seminal vesicle invation');\n",
    "legend(['No seminal vesicle invasion', 'Seminal vesicle incation'])\n",
    "ylim(-0.01,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two level cross validation for KNN - Greta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526, 15.789473684210526]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = [1, 2, 3] # Change here for different nearest neighbour crossvalidation\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "        counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "        top_count = np.argmax(counts)\n",
    "        # Only use the count from the last iteration! \n",
    "        optimal_K = K_KNN[top_count]\n",
    "        \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for KNN - Naia 2018-11-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[25.833333333333336, 21.75, 21.833333333333332, 17.833333333333332, 19.083333333333332, 20.5, 25.583333333333332, 20.5, 24.25, 21.75, 25.583333333333332, 21.75, 24.25, 21.75, 19.166666666666668, 19.25, 23.0, 20.5, 21.75, 20.5, 24.25, 21.75, 21.75, 19.25, 21.75, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25, 19.25]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [30.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[32.5, 23.5, 27.25, 28.5, 27.166666666666668, 28.583333333333332, 27.333333333333332, 23.583333333333332, 24.833333333333332, 21.0, 23.583333333333332, 23.5, 24.833333333333332, 22.166666666666668, 23.5, 20.916666666666668, 19.666666666666668, 20.916666666666668, 18.333333333333332, 22.166666666666668, 20.916666666666668, 22.166666666666668, 20.916666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668, 22.166666666666668]\n",
      "The index of optimal KNN value is: 18\n",
      "The optimal KNN value across inner CV folds is: 19\n",
      "Errors for each outer CV fold: [30.0, 20.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[19.083333333333332, 16.5, 20.5, 20.333333333333332, 20.333333333333332, 19.083333333333332, 19.083333333333332, 17.833333333333332, 19.166666666666668, 16.583333333333332, 16.583333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332, 17.833333333333332]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [30.0, 20.0, 36.8421052631579]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[26.916666666666668, 21.75, 23.0, 25.5, 29.333333333333332, 24.25, 22.916666666666668, 24.166666666666668, 28.083333333333332, 26.75, 29.25, 27.916666666666668, 26.666666666666668, 26.666666666666668, 25.25, 25.416666666666668, 25.333333333333332, 22.833333333333332, 21.583333333333332, 21.5, 20.25, 22.833333333333332, 21.583333333333332, 24.166666666666668, 21.666666666666668, 22.916666666666668, 24.25, 24.166666666666668, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332]\n",
      "The index of optimal KNN value is: 20\n",
      "The optimal KNN value across inner CV folds is: 21\n",
      "Errors for each outer CV fold: [30.0, 20.0, 36.8421052631579, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[33.333333333333336, 24.5, 29.583333333333332, 24.416666666666668, 29.5, 26.916666666666668, 28.0, 30.75, 30.666666666666668, 29.5, 32.083333333333336, 32.083333333333336, 35.833333333333336, 28.333333333333332, 29.583333333333332, 28.333333333333332, 29.583333333333332, 30.833333333333332, 29.5, 25.75, 27.0, 28.333333333333332, 27.083333333333332, 28.333333333333332, 27.083333333333332, 27.083333333333332, 28.333333333333332, 28.333333333333332, 27.083333333333332, 27.083333333333332, 27.083333333333332, 27.083333333333332, 27.083333333333332, 25.833333333333332, 25.833333333333332, 25.833333333333332, 25.833333333333332, 25.833333333333332, 25.833333333333332, 25.833333333333332]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [30.0, 20.0, 36.8421052631579, 15.789473684210526, 5.2631578947368425]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "                       \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.616666666666667\n",
      "22.3\n",
      "23.983333333333334\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0, 10.526315789473685]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13, 1, 12, 3, 13, 0]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "errorKNN_inner_GT=[]\n",
    "errorKNN_outer_GT = []\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = []\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = range(1,41)\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner_GT = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner_GT) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "    print(min_indices)\n",
    "    counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "    top_count = np.argmax(counts)\n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    # Only use the count from the last iteration! \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=1, p=dist);\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer_GT = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer_GT)\n",
    "    print(error_outer)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

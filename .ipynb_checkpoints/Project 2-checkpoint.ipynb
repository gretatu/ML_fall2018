{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this application is to solve relevant classification and regression problems for the prostate dataset for use in the project in 02450 Intro to Machine Learning\n",
    "\n",
    "Author: Naia Wright\n",
    "\n",
    "Reviewed by:  \n",
    "\n",
    "Last modified: 28/10/18, 09:39\n",
    "\n",
    "#### Change-log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "\n",
    "from matplotlib.pyplot import figure, boxplot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection, tree\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, xlabel, ylabel, show, clim\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n",
    "\n",
    "from statistics import mean\n",
    "import graphviz\n",
    "from numpy import array\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a method for importing a spread_sheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, sheet):\n",
    "    \"\"\"\n",
    "    Method for importing data from a spreadsheet.\n",
    "\n",
    "    :param path: full path to the spreadsheet to load\n",
    "    :param sheet: name of the sheet in the workbook that is loaded\n",
    "    :return: pandas dataFrame with imported data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    out = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path and sheet name in the prostate workbook\n",
    "#filePath = 'C:/Users/PeterBakke/Documents/git/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/Greta/Documents/Github/ML_fall2018/Data/Prostate.xlsx'\n",
    "filePath = 'C:/Users/narisa/Documents/GitHub/ML_fall2018/Data/Prostate.xlsx'\n",
    "sheet = 'Sheet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prostate data into dataFrame\n",
    "myData = DataLoader(path=filePath, sheet=sheet)\n",
    "\n",
    "# delete irrelevant columns\n",
    "del myData['ID']\n",
    "del myData['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol', 'lWeight', 'Age', 'lBPH', 'SVI', 'lCP', 'Gleason', 'pgg45', 'lPSA']\n",
      "{6: 0, 7: 1, 8: 2, 9: 3}\n"
     ]
    }
   ],
   "source": [
    "# extract class names and encode with integers (dict)\n",
    "\n",
    "classLabels = myData['Gleason'].values.tolist()\n",
    "classNames = sorted(set(classLabels))\n",
    "classDict = dict(zip(classNames, range(4)))\n",
    "\n",
    "#del myData['Gleason']\n",
    "\n",
    "attributeNames = list(myData.columns.values)\n",
    "\n",
    "print(attributeNames)\n",
    "print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector y, convert to NumPy array\n",
    "y = np.asarray([classDict[value] for value in classLabels])\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "X = myData.values\n",
    "\n",
    "# Compute values of N, M and C\n",
    "N = len(y)\n",
    "M = len(attributeNames)\n",
    "C = len(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.79818495e-01  2.76945900e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -4.30782900e-01]\n",
      " [-9.94252273e-01  3.31962600e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [-5.10825624e-01  2.69124300e+00  7.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "  -1.62518900e-01]\n",
      " [-1.20397280e+00  3.28278900e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [ 7.51416089e-01  3.43237300e+00  6.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.71563600e-01]\n",
      " [-1.04982212e+00  3.22882600e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 7.37164066e-01  3.47351800e+00  6.40000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 6.93147181e-01  3.53950900e+00  5.80000000e+01  1.53686722e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   8.54415300e-01]\n",
      " [-7.76528789e-01  3.53950900e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.23143551e-01  3.24454400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.54642218e-01  3.60413800e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [-1.34707365e+00  3.59868100e+00  6.30000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [ 1.61342993e+00  3.02286100e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.26694760e+00]\n",
      " [ 1.47704872e+00  2.99822900e+00  6.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   1.34807310e+00]\n",
      " [ 1.20597081e+00  3.44201900e+00  5.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  5.00000000e+00\n",
      "   1.39871690e+00]\n",
      " [ 1.54115907e+00  3.06105200e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.44691900e+00]\n",
      " [-4.15515444e-01  3.51601300e+00  7.00000000e+01  1.24415459e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.47017580e+00]\n",
      " [ 2.28848617e+00  3.64935900e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.49290410e+00]\n",
      " [-5.62118918e-01  3.26766600e+00  4.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.55814460e+00]\n",
      " [ 1.82321557e-01  3.82537500e+00  7.00000000e+01  1.65822808e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.59938760e+00]\n",
      " [ 1.14740245e+00  3.41936500e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.63899670e+00]\n",
      " [ 2.05923883e+00  3.50104300e+00  6.00000000e+01  1.47476301e+00\n",
      "   0.00000000e+00  1.34807315e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.65822810e+00]\n",
      " [-5.44727175e-01  3.37588000e+00  5.90000000e+01 -7.98507700e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.69561560e+00]\n",
      " [ 1.78170913e+00  3.45157400e+00  6.30000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  1.17865500e+00  7.00000000e+00  6.00000000e+01\n",
      "   1.71379790e+00]\n",
      " [ 3.85262401e-01  3.66740000e+00  6.90000000e+01  1.59938758e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.73165550e+00]\n",
      " [ 1.44691898e+00  3.12456500e+00  6.80000000e+01  3.00104590e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.76644170e+00]\n",
      " [ 5.12823626e-01  3.71965100e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  7.00000000e+01\n",
      "   1.80005830e+00]\n",
      " [-4.00477567e-01  3.86597900e+00  6.70000000e+01  1.81645208e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.81645210e+00]\n",
      " [ 1.04027671e+00  3.12895100e+00  6.70000000e+01  2.23143550e-01\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  8.00000000e+01\n",
      "   1.84845480e+00]\n",
      " [ 2.40964417e+00  3.37588000e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.61938824e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.89461690e+00]\n",
      " [ 2.85178942e-01  4.09016900e+00  6.50000000e+01  1.96290773e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.92424870e+00]\n",
      " [ 1.82321557e-01  3.80443800e+00  6.50000000e+01  1.70474809e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 1.27536280e+00  3.03735400e+00  7.10000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 9.95033100e-03  3.26766600e+00  5.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.02154760e+00]\n",
      " [-1.00503360e-02  3.21687400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.04769280e+00]\n",
      " [ 1.30833282e+00  4.11985000e+00  6.40000000e+01  2.17133681e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.08567210e+00]\n",
      " [ 1.42310833e+00  3.65713100e+00  7.30000000e+01 -5.79818500e-01\n",
      "   0.00000000e+00  1.65822808e+00  8.00000000e+00  1.50000000e+01\n",
      "   2.15755930e+00]\n",
      " [ 4.57424847e-01  2.37490600e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.19165350e+00]\n",
      " [ 2.66095859e+00  4.08513600e+00  6.80000000e+01  1.37371558e+00\n",
      "   1.00000000e+00  1.83258146e+00  7.00000000e+00  3.50000000e+01\n",
      "   2.21375390e+00]\n",
      " [ 7.97507196e-01  3.01308100e+00  5.60000000e+01  9.36093360e-01\n",
      "   0.00000000e+00 -1.62518930e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.27726730e+00]\n",
      " [ 6.20576488e-01  3.14199500e+00  6.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  9.00000000e+00  8.00000000e+01\n",
      "   2.29757260e+00]\n",
      " [ 1.44220199e+00  3.68261000e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   2.30757260e+00]\n",
      " [ 5.82215620e-01  3.86597900e+00  6.20000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.32727770e+00]\n",
      " [ 1.77155676e+00  3.89690900e+00  6.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  6.00000000e+00\n",
      "   2.37490580e+00]\n",
      " [ 1.48613970e+00  3.40949600e+00  6.60000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.52172060e+00]\n",
      " [ 1.66392610e+00  3.39282900e+00  6.10000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.55334380e+00]\n",
      " [ 2.72785283e+00  3.99544500e+00  7.90000000e+01  1.87946505e+00\n",
      "   1.00000000e+00  2.65675691e+00  9.00000000e+00  1.00000000e+02\n",
      "   2.56878810e+00]\n",
      " [ 1.16315081e+00  4.03512500e+00  6.80000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  4.00000000e+01\n",
      "   2.56878810e+00]\n",
      " [ 1.74571553e+00  3.49802200e+00  4.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.22082992e+00  3.56812300e+00  7.00000000e+01  1.37371558e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.09192330e+00  3.99360300e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+01\n",
      "   2.65675690e+00]\n",
      " [ 1.66013103e+00  4.23483100e+00  6.40000000e+01  2.07317193e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.67759100e+00]\n",
      " [ 5.12823626e-01  3.63363100e+00  6.40000000e+01  1.49290410e+00\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  7.00000000e+01\n",
      "   2.68444030e+00]\n",
      " [ 2.12704052e+00  4.12147300e+00  6.80000000e+01  1.76644166e+00\n",
      "   0.00000000e+00  1.44691898e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.69124310e+00]\n",
      " [ 3.15359036e+00  3.51601300e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.70471130e+00]\n",
      " [ 1.26694760e+00  4.28013200e+00  6.60000000e+01  2.12226154e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.71800050e+00]\n",
      " [ 9.74559640e-01  2.86505400e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  4.00000000e+00\n",
      "   2.78809290e+00]\n",
      " [ 4.63734016e-01  3.76468200e+00  4.90000000e+01  1.42310833e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.79422790e+00]\n",
      " [ 5.42324291e-01  4.17822600e+00  7.00000000e+01  4.38254930e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   2.80638610e+00]\n",
      " [ 1.06125650e+00  3.85121100e+00  6.10000000e+01  1.29472717e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.81241020e+00]\n",
      " [ 4.57424847e-01  4.52450200e+00  7.30000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.84199820e+00]\n",
      " [ 1.99741771e+00  3.71965100e+00  6.30000000e+01  1.61938824e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.77570885e+00  3.52488900e+00  7.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.55814462e+00  9.00000000e+00  9.50000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.03470565e+00  3.91701100e+00  6.60000000e+01  2.00821403e+00\n",
      "   1.00000000e+00  2.11021320e+00  7.00000000e+00  6.00000000e+01\n",
      "   2.88200350e+00]\n",
      " [ 2.07317193e+00  3.62300700e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.88200350e+00]\n",
      " [ 1.45861502e+00  3.83622100e+00  6.10000000e+01  1.32175584e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.88759010e+00]\n",
      " [ 2.02287119e+00  3.87846600e+00  6.80000000e+01  1.78339122e+00\n",
      "   0.00000000e+00  1.32175584e+00  7.00000000e+00  7.00000000e+01\n",
      "   2.92046980e+00]\n",
      " [ 2.19833507e+00  4.05091500e+00  7.20000000e+01  2.30757263e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  1.00000000e+01\n",
      "   2.96269240e+00]\n",
      " [-4.46287103e-01  4.40854700e+00  6.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.96269240e+00]\n",
      " [ 1.19392247e+00  4.78038300e+00  7.20000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.97297530e+00]\n",
      " [ 1.86408013e+00  3.59319400e+00  6.00000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.01308090e+00]\n",
      " [ 1.16002092e+00  3.34109300e+00  7.70000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.50000000e+01\n",
      "   3.03735390e+00]\n",
      " [ 1.21491274e+00  3.82537500e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.23143550e-01  7.00000000e+00  2.00000000e+01\n",
      "   3.05635690e+00]\n",
      " [ 1.83896107e+00  3.23671600e+00  6.00000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  1.17865500e+00  9.00000000e+00  9.00000000e+01\n",
      "   3.07500550e+00]\n",
      " [ 2.99922616e+00  3.84908300e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  2.00000000e+01\n",
      "   3.27525620e+00]\n",
      " [ 3.14113048e+00  3.26384900e+00  6.80000000e+01 -5.12932900e-02\n",
      "   1.00000000e+00  2.42036813e+00  7.00000000e+00  5.00000000e+01\n",
      "   3.33754740e+00]\n",
      " [ 2.01089500e+00  4.43378900e+00  7.20000000e+01  2.12226154e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  6.00000000e+01\n",
      "   3.39282910e+00]\n",
      " [ 2.53765721e+00  4.35478400e+00  7.80000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   3.43559880e+00]\n",
      " [ 2.64830020e+00  3.58212900e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.58399755e+00  7.00000000e+00  7.00000000e+01\n",
      "   3.45789270e+00]\n",
      " [ 2.77944020e+00  3.82319200e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  7.00000000e+00  5.00000000e+01\n",
      "   3.51303690e+00]\n",
      " [ 1.46787435e+00  3.07037600e+00  6.60000000e+01  5.59615790e-01\n",
      "   0.00000000e+00  2.23143550e-01  7.00000000e+00  4.00000000e+01\n",
      "   3.51601310e+00]\n",
      " [ 2.51365606e+00  3.47351800e+00  5.70000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.53076260e+00]\n",
      " [ 2.61300665e+00  3.88875400e+00  7.70000000e+01 -5.27632740e-01\n",
      "   1.00000000e+00  5.59615790e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.56529840e+00]\n",
      " [ 2.67759099e+00  3.83837600e+00  6.50000000e+01  1.11514159e+00\n",
      "   0.00000000e+00  1.74919985e+00  9.00000000e+00  7.00000000e+01\n",
      "   3.57094020e+00]\n",
      " [ 1.56234630e+00  3.70990700e+00  6.00000000e+01  1.69561561e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.58767690e+00]\n",
      " [ 3.30284926e+00  3.51898000e+00  6.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.63098550e+00]\n",
      " [ 2.02419307e+00  3.73169900e+00  5.80000000e+01  1.63899671e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.68009090e+00]\n",
      " [ 1.73165554e+00  3.36901800e+00  6.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  3.00104590e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.71235180e+00]\n",
      " [ 2.80759383e+00  4.71805200e+00  6.50000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.98434370e+00]\n",
      " [ 1.56234630e+00  3.69511000e+00  7.60000000e+01  9.36093360e-01\n",
      "   1.00000000e+00  8.10930220e-01  7.00000000e+00  7.50000000e+01\n",
      "   3.99360300e+00]\n",
      " [ 3.24649099e+00  4.10181700e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   4.02980600e+00]\n",
      " [ 2.53290285e+00  3.67756600e+00  6.10000000e+01  1.34807315e+00\n",
      "   1.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   4.12955080e+00]\n",
      " [ 2.83026783e+00  3.87639600e+00  6.80000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   4.38514680e+00]\n",
      " [ 3.82100361e+00  3.89690900e+00  4.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.16905370e+00  7.00000000e+00  4.00000000e+01\n",
      "   4.68444340e+00]\n",
      " [ 2.90744736e+00  3.39618500e+00  5.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  1.00000000e+01\n",
      "   5.14312450e+00]\n",
      " [ 2.88256357e+00  3.77391000e+00  6.80000000e+01  1.55814462e+00\n",
      "   1.00000000e+00  1.55814462e+00  7.00000000e+00  8.00000000e+01\n",
      "   5.47750900e+00]\n",
      " [ 3.47196645e+00  3.97499800e+00  6.80000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  2.90416508e+00  7.00000000e+00  2.00000000e+01\n",
      "   5.58293220e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data with mean and std\n",
    "Y = (X - np.ones((N,1))*X.mean(axis=0)) / X.std(axis=0)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.79818495e-01  2.76945900e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -4.30782900e-01]\n",
      " [-9.94252273e-01  3.31962600e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [-5.10825624e-01  2.69124300e+00  7.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "  -1.62518900e-01]\n",
      " [-1.20397280e+00  3.28278900e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [ 7.51416089e-01  3.43237300e+00  6.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.71563600e-01]\n",
      " [-1.04982212e+00  3.22882600e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 7.37164066e-01  3.47351800e+00  6.40000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 6.93147181e-01  3.53950900e+00  5.80000000e+01  1.53686722e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   8.54415300e-01]\n",
      " [-7.76528789e-01  3.53950900e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.23143551e-01  3.24454400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.54642218e-01  3.60413800e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [-1.34707365e+00  3.59868100e+00  6.30000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [ 1.61342993e+00  3.02286100e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.26694760e+00]\n",
      " [ 1.47704872e+00  2.99822900e+00  6.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   1.34807310e+00]\n",
      " [ 1.20597081e+00  3.44201900e+00  5.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  5.00000000e+00\n",
      "   1.39871690e+00]\n",
      " [ 1.54115907e+00  3.06105200e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.44691900e+00]\n",
      " [-4.15515444e-01  3.51601300e+00  7.00000000e+01  1.24415459e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.47017580e+00]\n",
      " [ 2.28848617e+00  3.64935900e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.49290410e+00]\n",
      " [-5.62118918e-01  3.26766600e+00  4.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.55814460e+00]\n",
      " [ 1.82321557e-01  3.82537500e+00  7.00000000e+01  1.65822808e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.59938760e+00]\n",
      " [ 1.14740245e+00  3.41936500e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.63899670e+00]\n",
      " [ 2.05923883e+00  3.50104300e+00  6.00000000e+01  1.47476301e+00\n",
      "   0.00000000e+00  1.34807315e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.65822810e+00]\n",
      " [-5.44727175e-01  3.37588000e+00  5.90000000e+01 -7.98507700e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.69561560e+00]\n",
      " [ 1.78170913e+00  3.45157400e+00  6.30000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  1.17865500e+00  7.00000000e+00  6.00000000e+01\n",
      "   1.71379790e+00]\n",
      " [ 3.85262401e-01  3.66740000e+00  6.90000000e+01  1.59938758e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.73165550e+00]\n",
      " [ 1.44691898e+00  3.12456500e+00  6.80000000e+01  3.00104590e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.76644170e+00]\n",
      " [ 5.12823626e-01  3.71965100e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  7.00000000e+01\n",
      "   1.80005830e+00]\n",
      " [-4.00477567e-01  3.86597900e+00  6.70000000e+01  1.81645208e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.81645210e+00]\n",
      " [ 1.04027671e+00  3.12895100e+00  6.70000000e+01  2.23143550e-01\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  8.00000000e+01\n",
      "   1.84845480e+00]\n",
      " [ 2.40964417e+00  3.37588000e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.61938824e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.89461690e+00]\n",
      " [ 2.85178942e-01  4.09016900e+00  6.50000000e+01  1.96290773e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.92424870e+00]\n",
      " [ 1.82321557e-01  3.80443800e+00  6.50000000e+01  1.70474809e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 1.27536280e+00  3.03735400e+00  7.10000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 9.95033100e-03  3.26766600e+00  5.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.02154760e+00]\n",
      " [-1.00503360e-02  3.21687400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.04769280e+00]\n",
      " [ 1.30833282e+00  4.11985000e+00  6.40000000e+01  2.17133681e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.08567210e+00]\n",
      " [ 1.42310833e+00  3.65713100e+00  7.30000000e+01 -5.79818500e-01\n",
      "   0.00000000e+00  1.65822808e+00  8.00000000e+00  1.50000000e+01\n",
      "   2.15755930e+00]\n",
      " [ 4.57424847e-01  2.37490600e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.19165350e+00]\n",
      " [ 2.66095859e+00  4.08513600e+00  6.80000000e+01  1.37371558e+00\n",
      "   1.00000000e+00  1.83258146e+00  7.00000000e+00  3.50000000e+01\n",
      "   2.21375390e+00]\n",
      " [ 7.97507196e-01  3.01308100e+00  5.60000000e+01  9.36093360e-01\n",
      "   0.00000000e+00 -1.62518930e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.27726730e+00]\n",
      " [ 6.20576488e-01  3.14199500e+00  6.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  9.00000000e+00  8.00000000e+01\n",
      "   2.29757260e+00]\n",
      " [ 1.44220199e+00  3.68261000e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   2.30757260e+00]\n",
      " [ 5.82215620e-01  3.86597900e+00  6.20000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.32727770e+00]\n",
      " [ 1.77155676e+00  3.89690900e+00  6.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  6.00000000e+00\n",
      "   2.37490580e+00]\n",
      " [ 1.48613970e+00  3.40949600e+00  6.60000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.52172060e+00]\n",
      " [ 1.66392610e+00  3.39282900e+00  6.10000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.55334380e+00]\n",
      " [ 2.72785283e+00  3.99544500e+00  7.90000000e+01  1.87946505e+00\n",
      "   1.00000000e+00  2.65675691e+00  9.00000000e+00  1.00000000e+02\n",
      "   2.56878810e+00]\n",
      " [ 1.16315081e+00  4.03512500e+00  6.80000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  4.00000000e+01\n",
      "   2.56878810e+00]\n",
      " [ 1.74571553e+00  3.49802200e+00  4.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.22082992e+00  3.56812300e+00  7.00000000e+01  1.37371558e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.09192330e+00  3.99360300e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+01\n",
      "   2.65675690e+00]\n",
      " [ 1.66013103e+00  4.23483100e+00  6.40000000e+01  2.07317193e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.67759100e+00]\n",
      " [ 5.12823626e-01  3.63363100e+00  6.40000000e+01  1.49290410e+00\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  7.00000000e+01\n",
      "   2.68444030e+00]\n",
      " [ 2.12704052e+00  4.12147300e+00  6.80000000e+01  1.76644166e+00\n",
      "   0.00000000e+00  1.44691898e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.69124310e+00]\n",
      " [ 3.15359036e+00  3.51601300e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.70471130e+00]\n",
      " [ 1.26694760e+00  4.28013200e+00  6.60000000e+01  2.12226154e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.71800050e+00]\n",
      " [ 9.74559640e-01  2.86505400e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  4.00000000e+00\n",
      "   2.78809290e+00]\n",
      " [ 4.63734016e-01  3.76468200e+00  4.90000000e+01  1.42310833e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.79422790e+00]\n",
      " [ 5.42324291e-01  4.17822600e+00  7.00000000e+01  4.38254930e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   2.80638610e+00]\n",
      " [ 1.06125650e+00  3.85121100e+00  6.10000000e+01  1.29472717e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.81241020e+00]\n",
      " [ 4.57424847e-01  4.52450200e+00  7.30000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.84199820e+00]\n",
      " [ 1.99741771e+00  3.71965100e+00  6.30000000e+01  1.61938824e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.77570885e+00  3.52488900e+00  7.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.55814462e+00  9.00000000e+00  9.50000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.03470565e+00  3.91701100e+00  6.60000000e+01  2.00821403e+00\n",
      "   1.00000000e+00  2.11021320e+00  7.00000000e+00  6.00000000e+01\n",
      "   2.88200350e+00]\n",
      " [ 2.07317193e+00  3.62300700e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.88200350e+00]\n",
      " [ 1.45861502e+00  3.83622100e+00  6.10000000e+01  1.32175584e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.88759010e+00]\n",
      " [ 2.02287119e+00  3.87846600e+00  6.80000000e+01  1.78339122e+00\n",
      "   0.00000000e+00  1.32175584e+00  7.00000000e+00  7.00000000e+01\n",
      "   2.92046980e+00]\n",
      " [ 2.19833507e+00  4.05091500e+00  7.20000000e+01  2.30757263e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  1.00000000e+01\n",
      "   2.96269240e+00]\n",
      " [-4.46287103e-01  4.40854700e+00  6.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.96269240e+00]\n",
      " [ 1.19392247e+00  4.78038300e+00  7.20000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.97297530e+00]\n",
      " [ 1.86408013e+00  3.59319400e+00  6.00000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.01308090e+00]\n",
      " [ 1.16002092e+00  3.34109300e+00  7.70000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.50000000e+01\n",
      "   3.03735390e+00]\n",
      " [ 1.21491274e+00  3.82537500e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.23143550e-01  7.00000000e+00  2.00000000e+01\n",
      "   3.05635690e+00]\n",
      " [ 1.83896107e+00  3.23671600e+00  6.00000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  1.17865500e+00  9.00000000e+00  9.00000000e+01\n",
      "   3.07500550e+00]\n",
      " [ 2.99922616e+00  3.84908300e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  2.00000000e+01\n",
      "   3.27525620e+00]\n",
      " [ 3.14113048e+00  3.26384900e+00  6.80000000e+01 -5.12932900e-02\n",
      "   1.00000000e+00  2.42036813e+00  7.00000000e+00  5.00000000e+01\n",
      "   3.33754740e+00]\n",
      " [ 2.01089500e+00  4.43378900e+00  7.20000000e+01  2.12226154e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  6.00000000e+01\n",
      "   3.39282910e+00]\n",
      " [ 2.53765721e+00  4.35478400e+00  7.80000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   3.43559880e+00]\n",
      " [ 2.64830020e+00  3.58212900e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.58399755e+00  7.00000000e+00  7.00000000e+01\n",
      "   3.45789270e+00]\n",
      " [ 2.77944020e+00  3.82319200e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  7.00000000e+00  5.00000000e+01\n",
      "   3.51303690e+00]\n",
      " [ 1.46787435e+00  3.07037600e+00  6.60000000e+01  5.59615790e-01\n",
      "   0.00000000e+00  2.23143550e-01  7.00000000e+00  4.00000000e+01\n",
      "   3.51601310e+00]\n",
      " [ 2.51365606e+00  3.47351800e+00  5.70000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.53076260e+00]\n",
      " [ 2.61300665e+00  3.88875400e+00  7.70000000e+01 -5.27632740e-01\n",
      "   1.00000000e+00  5.59615790e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.56529840e+00]\n",
      " [ 2.67759099e+00  3.83837600e+00  6.50000000e+01  1.11514159e+00\n",
      "   0.00000000e+00  1.74919985e+00  9.00000000e+00  7.00000000e+01\n",
      "   3.57094020e+00]\n",
      " [ 1.56234630e+00  3.70990700e+00  6.00000000e+01  1.69561561e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.58767690e+00]\n",
      " [ 3.30284926e+00  3.51898000e+00  6.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.63098550e+00]\n",
      " [ 2.02419307e+00  3.73169900e+00  5.80000000e+01  1.63899671e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.68009090e+00]\n",
      " [ 1.73165554e+00  3.36901800e+00  6.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  3.00104590e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.71235180e+00]\n",
      " [ 2.80759383e+00  4.71805200e+00  6.50000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.98434370e+00]\n",
      " [ 1.56234630e+00  3.69511000e+00  7.60000000e+01  9.36093360e-01\n",
      "   1.00000000e+00  8.10930220e-01  7.00000000e+00  7.50000000e+01\n",
      "   3.99360300e+00]\n",
      " [ 3.24649099e+00  4.10181700e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   4.02980600e+00]\n",
      " [ 2.53290285e+00  3.67756600e+00  6.10000000e+01  1.34807315e+00\n",
      "   1.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   4.12955080e+00]\n",
      " [ 2.83026783e+00  3.87639600e+00  6.80000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   4.38514680e+00]\n",
      " [ 3.82100361e+00  3.89690900e+00  4.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.16905370e+00  7.00000000e+00  4.00000000e+01\n",
      "   4.68444340e+00]\n",
      " [ 2.90744736e+00  3.39618500e+00  5.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  1.00000000e+01\n",
      "   5.14312450e+00]\n",
      " [ 2.88256357e+00  3.77391000e+00  6.80000000e+01  1.55814462e+00\n",
      "   1.00000000e+00  1.55814462e+00  7.00000000e+00  8.00000000e+01\n",
      "   5.47750900e+00]\n",
      " [ 3.47196645e+00  3.97499800e+00  6.80000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  2.90416508e+00  7.00000000e+00  2.00000000e+01\n",
      "   5.58293220e+00]]\n",
      "['lCaVol' 'lWeight' 'Age' 'lBPH' 'lCP' 'Gleason' 'pgg45' 'lPSA']\n"
     ]
    }
   ],
   "source": [
    "# Remove attribute 5 (SVI) from X\n",
    "X_classification = X[:,[0,1,2,3,5,6,7,8]]\n",
    "print(X)\n",
    "# Use attribute 5 (SVI) as y\n",
    "y_classification = X[:,4]\n",
    "# Remove attribute 5 (SVI) from attribute names\n",
    "\n",
    "attributeNames_classification = np.array(attributeNames)[[0, 1, 2, 3, 5, 6, 7, 8]]\n",
    "print(attributeNames_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for KNN - Naia 2018-11-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[26.166666666666668, 18.25, 26.333333333333336, 25.0, 22.416666666666668, 23.583333333333332, 26.166666666666668, 27.5, 26.25, 25.0, 27.5, 26.166666666666668, 26.166666666666668, 23.5, 26.166666666666668, 22.166666666666668, 22.166666666666668, 19.583333333333336, 18.25, 18.25, 18.25, 18.25, 18.25, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336, 19.583333333333336]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [25.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[27.166666666666668, 23.166666666666668, 25.833333333333336, 27.166666666666668, 28.5, 24.583333333333332, 32.333333333333336, 31.0, 32.333333333333336, 25.75, 33.66666666666667, 29.75, 31.083333333333336, 31.083333333333336, 31.0, 27.166666666666668, 28.416666666666668, 25.833333333333332, 27.083333333333336, 25.833333333333332, 25.833333333333332, 25.833333333333332, 24.5, 24.5, 25.833333333333332, 27.083333333333332, 27.0, 25.75, 27.0, 27.083333333333332, 27.083333333333332, 27.083333333333332, 27.083333333333332, 25.75, 25.75, 25.75, 25.75, 25.75, 25.75, 25.75]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [25.0, 5.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[30.833333333333332, 20.5, 23.083333333333332, 21.75, 23.166666666666668, 20.583333333333332, 23.166666666666668, 20.5, 20.583333333333332, 20.5, 26.916666666666668, 20.5, 25.583333333333336, 20.5, 20.5, 21.75, 23.0, 20.5, 21.75, 20.5, 20.5, 20.5, 20.5, 21.75, 21.75, 20.5, 21.75, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [25.0, 5.0, 26.31578947368421]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[19.25, 18.0, 24.25, 21.75, 20.416666666666668, 24.416666666666668, 21.916666666666668, 21.916666666666668, 23.083333333333332, 16.833333333333332, 16.833333333333332, 20.583333333333332, 19.333333333333332, 23.166666666666668, 24.416666666666668, 20.666666666666668, 20.666666666666668, 21.916666666666668, 19.333333333333332, 21.916666666666668, 21.916666666666668, 20.666666666666668, 21.916666666666668, 23.166666666666668, 20.666666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668]\n",
      "The index of optimal KNN value is: 9\n",
      "The optimal KNN value across inner CV folds is: 10\n",
      "Errors for each outer CV fold: [25.0, 5.0, 26.31578947368421, 26.31578947368421]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[25.75, 16.833333333333332, 18.083333333333332, 21.833333333333332, 21.916666666666668, 19.25, 19.333333333333336, 20.583333333333332, 21.833333333333332, 19.166666666666668, 20.5, 19.166666666666668, 17.916666666666668, 19.166666666666668, 19.25, 17.916666666666668, 18.0, 19.25, 19.25, 20.5, 21.916666666666668, 21.833333333333332, 21.833333333333332, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5, 20.5]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [25.0, 5.0, 26.31578947368421, 26.31578947368421, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "                       \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "error_KNN = error_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[16.916666666666668, 14.166666666666666, 16.916666666666668, 19.583333333333336, 14.25, 15.5, 14.25, 19.583333333333332, 16.916666666666668, 16.916666666666668, 15.5, 15.5, 18.25, 12.916666666666668, 19.583333333333332, 19.416666666666668, 16.833333333333332, 22.166666666666668, 12.916666666666668]\n",
      "The index of optimal tc value is: 13\n",
      "The optimal tc value across inner CV folds is: 15\n",
      "Errors for each outer tc fold: [5.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[24.75, 23.333333333333332, 24.75, 29.833333333333332, 27.333333333333332, 27.333333333333332, 24.833333333333332, 27.333333333333332, 26.0, 24.666666666666668, 25.916666666666668, 26.0, 26.0, 24.666666666666668, 27.25, 26.083333333333332, 26.0, 26.083333333333332, 27.25]\n",
      "The index of optimal tc value is: 1\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [5.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.333333333333334, 16.5, 15.25, 14.0, 16.5, 14.0, 19.0, 19.0, 16.5, 12.75, 14.0, 16.5, 15.25, 14.0, 16.5, 15.25, 14.0, 12.75, 14.0]\n",
      "The index of optimal tc value is: 9\n",
      "The optimal tc value across inner CV folds is: 11\n",
      "Errors for each outer tc fold: [5.0, 15.0, 26.31578947368421]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.75, 18.166666666666668, 10.5, 14.416666666666668, 14.333333333333334, 12.916666666666666, 15.583333333333334, 15.666666666666668, 14.333333333333334, 15.583333333333334, 14.166666666666666, 13.0, 15.583333333333334, 16.833333333333332, 15.583333333333334, 15.583333333333334, 15.5, 15.583333333333334, 14.333333333333334]\n",
      "The index of optimal tc value is: 2\n",
      "The optimal tc value across inner CV folds is: 4\n",
      "Errors for each outer tc fold: [5.0, 15.0, 26.31578947368421, 42.10526315789474]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[13.083333333333334, 15.583333333333334, 14.333333333333334, 16.833333333333332, 14.333333333333334, 14.333333333333334, 15.5, 16.833333333333332, 14.333333333333334, 16.833333333333332, 13.0, 15.5, 16.833333333333332, 16.833333333333332, 15.5, 14.333333333333334, 13.0, 13.0, 16.833333333333332]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 12\n",
      "Errors for each outer tc fold: [5.0, 15.0, 26.31578947368421, 42.10526315789474, 10.526315789473685]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "print(tc)\n",
    "\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_tc = tc[top_count]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer))\n",
    "\n",
    "error_dct = error_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "[[-9.94252273e-01  3.31962600e+00  5.80000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00 -1.62518900e-01]\n",
      " [-5.10825624e-01  2.69124300e+00  7.40000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  7.00000000e+00  2.00000000e+01 -1.62518900e-01]\n",
      " [-1.20397280e+00  3.28278900e+00  5.80000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00 -1.62518900e-01]\n",
      " [ 7.51416089e-01  3.43237300e+00  6.20000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  3.71563600e-01]\n",
      " [-1.04982212e+00  3.22882600e+00  5.00000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  7.65467800e-01]\n",
      " [ 7.37164066e-01  3.47351800e+00  6.40000000e+01  6.15185640e-01\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  7.65467800e-01]\n",
      " [ 2.23143551e-01  3.24454400e+00  6.30000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.04731900e+00]\n",
      " [ 2.54642218e-01  3.60413800e+00  6.50000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.26694760e+00]\n",
      " [-1.34707365e+00  3.59868100e+00  6.30000000e+01  1.26694760e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.26694760e+00]\n",
      " [ 1.20597081e+00  3.44201900e+00  5.70000000e+01 -1.38629436e+00\n",
      "  -4.30782920e-01  7.00000000e+00  5.00000000e+00  1.39871690e+00]\n",
      " [ 1.54115907e+00  3.06105200e+00  6.60000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.44691900e+00]\n",
      " [-4.15515444e-01  3.51601300e+00  7.00000000e+01  1.24415459e+00\n",
      "  -5.97837000e-01  7.00000000e+00  3.00000000e+01  1.47017580e+00]\n",
      " [-5.62118918e-01  3.26766600e+00  4.10000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.55814460e+00]\n",
      " [ 1.14740245e+00  3.41936500e+00  5.90000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.63899670e+00]\n",
      " [ 2.05923883e+00  3.50104300e+00  6.00000000e+01  1.47476301e+00\n",
      "   1.34807315e+00  7.00000000e+00  2.00000000e+01  1.65822810e+00]\n",
      " [-5.44727175e-01  3.37588000e+00  5.90000000e+01 -7.98507700e-01\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  1.69561560e+00]\n",
      " [ 1.78170913e+00  3.45157400e+00  6.30000000e+01  4.38254930e-01\n",
      "   1.17865500e+00  7.00000000e+00  6.00000000e+01  1.71379790e+00]\n",
      " [-4.00477567e-01  3.86597900e+00  6.70000000e+01  1.81645208e+00\n",
      "  -1.38629436e+00  7.00000000e+00  2.00000000e+01  1.81645210e+00]\n",
      " [ 1.04027671e+00  3.12895100e+00  6.70000000e+01  2.23143550e-01\n",
      "   4.87901600e-02  7.00000000e+00  8.00000000e+01  1.84845480e+00]\n",
      " [ 2.40964417e+00  3.37588000e+00  6.50000000e+01 -1.38629436e+00\n",
      "   1.61938824e+00  6.00000000e+00  0.00000000e+00  1.89461690e+00]\n",
      " [ 1.82321557e-01  3.80443800e+00  6.50000000e+01  1.70474809e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.00821400e+00]\n",
      " [ 1.27536280e+00  3.03735400e+00  7.10000000e+01  1.26694760e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.00821400e+00]\n",
      " [ 9.95033100e-03  3.26766600e+00  5.40000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.02154760e+00]\n",
      " [ 1.42310833e+00  3.65713100e+00  7.30000000e+01 -5.79818500e-01\n",
      "   1.65822808e+00  8.00000000e+00  1.50000000e+01  2.15755930e+00]\n",
      " [ 4.57424847e-01  2.37490600e+00  6.40000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  7.00000000e+00  1.50000000e+01  2.19165350e+00]\n",
      " [ 2.66095859e+00  4.08513600e+00  6.80000000e+01  1.37371558e+00\n",
      "   1.83258146e+00  7.00000000e+00  3.50000000e+01  2.21375390e+00]\n",
      " [ 5.82215620e-01  3.86597900e+00  6.20000000e+01  1.71379793e+00\n",
      "  -4.30782920e-01  6.00000000e+00  0.00000000e+00  2.32727770e+00]\n",
      " [ 1.77155676e+00  3.89690900e+00  6.10000000e+01 -1.38629436e+00\n",
      "   8.10930220e-01  7.00000000e+00  6.00000000e+00  2.37490580e+00]\n",
      " [ 1.48613970e+00  3.40949600e+00  6.60000000e+01  1.74919985e+00\n",
      "  -4.30782920e-01  7.00000000e+00  2.00000000e+01  2.52172060e+00]\n",
      " [ 1.66392610e+00  3.39282900e+00  6.10000000e+01  6.15185640e-01\n",
      "  -1.38629436e+00  7.00000000e+00  1.50000000e+01  2.55334380e+00]\n",
      " [ 2.72785283e+00  3.99544500e+00  7.90000000e+01  1.87946505e+00\n",
      "   2.65675691e+00  9.00000000e+00  1.00000000e+02  2.56878810e+00]\n",
      " [ 1.74571553e+00  3.49802200e+00  4.30000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.59151640e+00]\n",
      " [ 1.22082992e+00  3.56812300e+00  7.00000000e+01  1.37371558e+00\n",
      "  -7.98507700e-01  6.00000000e+00  0.00000000e+00  2.59151640e+00]\n",
      " [ 1.66013103e+00  4.23483100e+00  6.40000000e+01  2.07317193e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.67759100e+00]\n",
      " [ 5.12823626e-01  3.63363100e+00  6.40000000e+01  1.49290410e+00\n",
      "   4.87901600e-02  7.00000000e+00  7.00000000e+01  2.68444030e+00]\n",
      " [ 4.63734016e-01  3.76468200e+00  4.90000000e+01  1.42310833e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.79422790e+00]\n",
      " [ 5.42324291e-01  4.17822600e+00  7.00000000e+01  4.38254930e-01\n",
      "  -1.38629436e+00  7.00000000e+00  2.00000000e+01  2.80638610e+00]\n",
      " [ 4.57424847e-01  4.52450200e+00  7.30000000e+01  2.32630162e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.84199820e+00]\n",
      " [ 2.77570885e+00  3.52488900e+00  7.20000000e+01 -1.38629436e+00\n",
      "   1.55814462e+00  9.00000000e+00  9.50000000e+01  2.85359250e+00]\n",
      " [ 2.07317193e+00  3.62300700e+00  6.40000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.88200350e+00]\n",
      " [ 1.45861502e+00  3.83622100e+00  6.10000000e+01  1.32175584e+00\n",
      "  -4.30782920e-01  7.00000000e+00  2.00000000e+01  2.88759010e+00]\n",
      " [ 2.19833507e+00  4.05091500e+00  7.20000000e+01  2.30757263e+00\n",
      "  -4.30782920e-01  7.00000000e+00  1.00000000e+01  2.96269240e+00]\n",
      " [-4.46287103e-01  4.40854700e+00  6.90000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  2.96269240e+00]\n",
      " [ 1.19392247e+00  4.78038300e+00  7.20000000e+01  2.32630162e+00\n",
      "  -7.98507700e-01  7.00000000e+00  5.00000000e+00  2.97297530e+00]\n",
      " [ 1.86408013e+00  3.59319400e+00  6.00000000e+01 -1.38629436e+00\n",
      "   1.32175584e+00  7.00000000e+00  6.00000000e+01  3.01308090e+00]\n",
      " [ 1.16002092e+00  3.34109300e+00  7.70000000e+01  1.74919985e+00\n",
      "  -1.38629436e+00  7.00000000e+00  2.50000000e+01  3.03735390e+00]\n",
      " [ 3.14113048e+00  3.26384900e+00  6.80000000e+01 -5.12932900e-02\n",
      "   2.42036813e+00  7.00000000e+00  5.00000000e+01  3.33754740e+00]\n",
      " [ 2.01089500e+00  4.43378900e+00  7.20000000e+01  2.12226154e+00\n",
      "   5.00775290e-01  7.00000000e+00  6.00000000e+01  3.39282910e+00]\n",
      " [ 2.53765721e+00  4.35478400e+00  7.80000000e+01  2.32630162e+00\n",
      "  -1.38629436e+00  7.00000000e+00  1.00000000e+01  3.43559880e+00]\n",
      " [ 2.77944020e+00  3.82319200e+00  6.30000000e+01 -1.38629436e+00\n",
      "   3.71563560e-01  7.00000000e+00  5.00000000e+01  3.51303690e+00]\n",
      " [ 1.46787435e+00  3.07037600e+00  6.60000000e+01  5.59615790e-01\n",
      "   2.23143550e-01  7.00000000e+00  4.00000000e+01  3.51601310e+00]\n",
      " [ 2.61300665e+00  3.88875400e+00  7.70000000e+01 -5.27632740e-01\n",
      "   5.59615790e-01  7.00000000e+00  3.00000000e+01  3.56529840e+00]\n",
      " [ 2.67759099e+00  3.83837600e+00  6.50000000e+01  1.11514159e+00\n",
      "   1.74919985e+00  9.00000000e+00  7.00000000e+01  3.57094020e+00]\n",
      " [ 1.56234630e+00  3.70990700e+00  6.00000000e+01  1.69561561e+00\n",
      "   8.10930220e-01  7.00000000e+00  3.00000000e+01  3.58767690e+00]\n",
      " [ 1.73165554e+00  3.36901800e+00  6.20000000e+01 -1.38629436e+00\n",
      "   3.00104590e-01  7.00000000e+00  3.00000000e+01  3.71235180e+00]\n",
      " [ 2.80759383e+00  4.71805200e+00  6.50000000e+01 -1.38629436e+00\n",
      "   2.46385324e+00  7.00000000e+00  6.00000000e+01  3.98434370e+00]\n",
      " [ 3.24649099e+00  4.10181700e+00  6.80000000e+01 -1.38629436e+00\n",
      "  -1.38629436e+00  6.00000000e+00  0.00000000e+00  4.02980600e+00]\n",
      " [ 3.82100361e+00  3.89690900e+00  4.40000000e+01 -1.38629436e+00\n",
      "   2.16905370e+00  7.00000000e+00  4.00000000e+01  4.68444340e+00]\n",
      " [ 2.90744736e+00  3.39618500e+00  5.20000000e+01 -1.38629436e+00\n",
      "   2.46385324e+00  7.00000000e+00  1.00000000e+01  5.14312450e+00]\n",
      " [ 2.88256357e+00  3.77391000e+00  6.80000000e+01  1.55814462e+00\n",
      "   1.55814462e+00  7.00000000e+00  8.00000000e+01  5.47750900e+00]\n",
      " [ 3.47196645e+00  3.97499800e+00  6.80000000e+01  4.38254930e-01\n",
      "   2.90416508e+00  7.00000000e+00  2.00000000e+01  5.58293220e+00]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-af75c218e0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mnbclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mnbclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mclassifier_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    602\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    603\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "### OBS. method can not use X values < 0\n",
    "\n",
    "## Crossvalidation for Naive Bayes\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = np.empty((1,1)) # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "\n",
    "# Naive Bayes classifier parameters\n",
    "alpha = [1]         # additive parameter (e.g. Laplace correction), lægges til da log bliver taget i MultinormilNB\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        print(X_train_inner) \n",
    "        for count, value in enumerate(alpha):\n",
    "            est_prior = True  # uniform prior (change to True to estimate prior from data)    \n",
    "                       \n",
    "            nbclassifier = MultinomialNB(alpha=alpha, fit_prior=est_prior);\n",
    "            nbclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(nbclassifier)\n",
    " \n",
    "            y_NB = nbclassifier.predict(X_test_inner);\n",
    "            errorNB_inner = 100*(y_NB!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['alpha_of_{0}'.format(value)].append(errorNB_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the alpha value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_alpha = alpha[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    nbclassifierOuter = MultinomialNB(alpha=optimal_alpha, fit_prior=est_prior); #Uses optimal_alpha, which was found in the inner CV loop\n",
    "    nbclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_NB_outer = nbclassifier.predict(X_test_outer);\n",
    "    errorNB_outer = 100*(y_NB_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorNB_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-validation error [%]')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c18d9f73c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "boxplot([error_KNN, error_dct])\n",
    "xlabel('K-Nearest Neighbors   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method selected: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Re-estimate of the model on all data for a maximum depth of 12 \n",
    "\n",
    "# Fit decision tree classifier, Gini split criterion, maximum depth of 12 on all data\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=12) \n",
    "dtc.fit(X_classification, y_classification.ravel())\n",
    "\n",
    "# New data object\n",
    "#new_data = np.array([-5, 2, 4, -1, -1, 5, 0, -3]).reshape(1,-1) # Gives 0 - No SVI\n",
    "new_data = np.array([3, 2, 4, -1, 2, 5, 0, -3]).reshape(1,-1) # Gives 1 - Yes SVI\n",
    "\n",
    "# Evalulate the decision tree for a new data object\n",
    "new_data_class = dtc.predict(new_data)[0]\n",
    "print(new_data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol' 'lWeight' 'Age' 'lBPH' 'lCP' 'Gleason' 'pgg45' 'lPSA']\n"
     ]
    }
   ],
   "source": [
    "print(attributeNames_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"634pt\" height=\"581pt\"\r\n",
       " viewBox=\"0.00 0.00 633.50 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-577 629.5,-577 629.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"441.5,-573 337.5,-573 337.5,-505 441.5,-505 441.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"389.5\" y=\"-557.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCP &lt;= 1.791</text>\r\n",
       "<text text-anchor=\"middle\" x=\"389.5\" y=\"-542.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.339</text>\r\n",
       "<text text-anchor=\"middle\" x=\"389.5\" y=\"-527.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 97</text>\r\n",
       "<text text-anchor=\"middle\" x=\"389.5\" y=\"-512.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [76, 21]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377,-469 276,-469 276,-401 377,-401 377,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 2.993</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.191</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 84</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [75, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M369.046,-504.884C363.764,-496.332 358.008,-487.013 352.486,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.3,-475.968 347.067,-469.299 349.344,-479.647 355.3,-475.968\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"341.317\" y=\"-489.929\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"507.5,-469 397.5,-469 397.5,-401 507.5,-401 507.5,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCaVol &lt;= 2.581</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 12]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.954,-504.884C415.236,-496.332 420.992,-487.013 426.514,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"429.656,-479.647 431.933,-469.299 423.7,-475.968 429.656,-479.647\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"437.683\" y=\"-489.929\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"257.5,-357.5 159.5,-357.5 159.5,-304.5 257.5,-304.5 257.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 66</text>\r\n",
       "<text text-anchor=\"middle\" x=\"208.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [66, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.189,-400.884C274.575,-389.116 259.279,-375.894 245.755,-364.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"247.877,-361.412 238.023,-357.52 243.3,-366.707 247.877,-361.412\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377,-365 276,-365 276,-297 377,-297 377,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lBPH &lt;= 1.599</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.5,-400.884C326.5,-392.778 326.5,-383.982 326.5,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"330,-375.299 326.5,-365.299 323,-375.299 330,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"267.5,-261 157.5,-261 157.5,-193 267.5,-193 267.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCaVol &lt;= 2.645</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M289.487,-296.884C279.234,-287.709 267.991,-277.65 257.343,-268.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"259.503,-265.359 249.717,-261.299 254.836,-270.576 259.503,-265.359\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377,-253.5 286,-253.5 286,-200.5 377,-200.5 377,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"331.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"331.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"331.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>3&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.123,-296.884C328.646,-286.216 329.228,-274.352 329.759,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.255,-263.679 330.249,-253.52 326.264,-263.337 333.255,-263.679\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"206.5,-157 92.5,-157 92.5,-89 206.5,-89 206.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lWeight &lt;= 3.154</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.219</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.046,-192.884C186.764,-184.332 181.008,-175.013 175.486,-166.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.3,-163.968 170.067,-157.299 172.344,-167.647 178.3,-163.968\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"326,-157 225,-157 225,-89 326,-89 326,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 4.207</text>\r\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.48</text>\r\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"275.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M232.954,-192.884C238.236,-184.332 243.992,-175.013 249.514,-166.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.656,-167.647 254.933,-157.299 246.7,-163.968 252.656,-167.647\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-53 0,-53 0,-0 91,-0 91,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.126,-88.9485C102.857,-79.6175 91.6916,-69.4722 81.4478,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.5788,-57.3713 73.824,-53.2367 78.8713,-62.5521 83.5788,-57.3713\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200,-53 109,-53 109,-0 200,-0 200,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.249,-88.9485C151.684,-80.7153 152.154,-71.848 152.596,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.105,-63.4077 153.138,-53.2367 149.115,-63.0378 156.105,-63.4077\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"313,-53 222,-53 222,-0 313,-0 313,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"267.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M272.702,-88.9485C271.997,-80.6238 271.238,-71.6509 270.522,-63.2027\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"274.01,-62.9058 269.679,-53.2367 267.035,-63.4963 274.01,-62.9058\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"422,-53 331,-53 331,-0 422,-0 422,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"376.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"376.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"376.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310.825,-88.9485C320.798,-79.6175 331.641,-69.4722 341.589,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.082,-62.6247 348.993,-53.2367 339.3,-57.5132 344.082,-62.6247\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"509.5,-365 395.5,-365 395.5,-297 509.5,-297 509.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lWeight &lt;= 3.597</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"452.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.5,-400.884C452.5,-392.778 452.5,-383.982 452.5,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456,-375.299 452.5,-365.299 449,-375.299 456,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"625.5,-357.5 527.5,-357.5 527.5,-304.5 625.5,-304.5 625.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"576.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"576.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"576.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 10]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>12&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M492.759,-400.884C507.199,-389.006 523.44,-375.646 537.749,-363.876\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"539.976,-366.576 545.476,-357.52 535.529,-361.17 539.976,-366.576\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"494,-253.5 403,-253.5 403,-200.5 494,-200.5 494,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"448.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"448.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"448.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M451.201,-296.884C450.783,-286.216 450.318,-274.352 449.893,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"453.39,-263.375 449.501,-253.52 446.395,-263.649 453.39,-263.375\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"603,-253.5 512,-253.5 512,-200.5 603,-200.5 603,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"557.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M486.59,-296.884C498.591,-285.226 512.061,-272.141 524.012,-260.532\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"526.495,-262.998 531.229,-253.52 521.618,-257.977 526.495,-262.998\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1c18da79fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export tree graph for visualization purposes:\n",
    "# (note: you can use i.e. Graphviz application to visualize the file)\n",
    "out = tree.export_graphviz(dtc, out_file='tree_gini.gvz', feature_names=attributeNames_classification)\n",
    "#graphviz.render('dot','png','tree_gini',quiet=False)\n",
    "src=graphviz.Source.from_file('tree_gini.gvz')\n",
    "## Comment in to automatically open pdf\n",
    "## Note. If you get an error (e.g. exit status 1), try closing the pdf file/viewer\n",
    "#src.render('../tree_gini', view=True)\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# zero rule algorithm for classification\n",
    "def Baseline_model(y_train, y_test):\n",
    "    prediction = stats.mode(y_train)[0]\n",
    "    predicted = [int(prediction) for i in range(len(y_test))]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-level-cross validation for dtc, KNN and baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[13.083333333333334, 13.0, 14.25, 15.583333333333334, 15.583333333333334, 16.916666666666668, 14.416666666666666, 14.333333333333334, 15.583333333333334, 16.916666666666668, 15.666666666666666, 18.083333333333332, 15.583333333333334, 13.083333333333334, 15.583333333333334, 13.083333333333334, 16.916666666666668, 15.583333333333334, 15.583333333333334]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 3\n",
      "Errors for each outer tc fold: [5.0]\n",
      "Inner_error_values are:[30.833333333333332, 20.583333333333332, 24.416666666666668, 27.083333333333336, 29.583333333333332, 27.083333333333332, 27.166666666666668, 25.916666666666668, 28.5, 27.166666666666668, 28.416666666666668, 24.583333333333336, 27.083333333333336, 22.083333333333336, 25.916666666666668, 23.333333333333336, 23.333333333333336, 22.083333333333336, 23.333333333333336, 23.333333333333336, 24.583333333333336, 24.583333333333336, 25.833333333333336, 23.333333333333336, 25.833333333333336, 22.083333333333336, 20.833333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336, 22.083333333333336]\n",
      "The index of optimal KNN value is: 10\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [15.0]\n",
      "Errors for baseline outer fold[20.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[13.166666666666668, 9.166666666666668, 10.583333333333334, 10.583333333333334, 13.083333333333334, 10.5, 9.25, 11.833333333333334, 11.75, 10.416666666666668, 10.5, 10.5, 10.416666666666668, 10.583333333333334, 6.583333333333333, 11.833333333333334, 9.166666666666668, 10.5, 9.166666666666668]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 16\n",
      "Errors for each outer tc fold: [5.0, 45.0]\n",
      "Inner_error_values are:[29.833333333333336, 24.916666666666668, 20.916666666666668, 21.0, 18.25, 20.916666666666668, 23.583333333333336, 24.916666666666668, 27.5, 24.833333333333336, 24.75, 23.583333333333336, 22.166666666666668, 22.333333333333336, 27.416666666666668, 24.916666666666668, 26.166666666666668, 24.833333333333336, 24.75, 19.75, 23.583333333333336, 22.333333333333336, 24.916666666666668, 24.833333333333336, 26.083333333333336, 23.583333333333336, 24.833333333333336, 21.083333333333336, 19.833333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336, 21.083333333333336]\n",
      "The index of optimal KNN value is: 10\n",
      "The optimal KNN value across inner CV folds is: 5\n",
      "Errors for each outer CV fold: [15.0, 35.0]\n",
      "Errors for baseline outer fold[20.0, 25.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[15.166666666666666, 15.25, 16.583333333333332, 16.583333333333332, 16.583333333333332, 19.166666666666668, 17.916666666666668, 17.833333333333332, 16.583333333333332, 19.166666666666668, 17.916666666666668, 17.916666666666668, 16.583333333333332, 16.666666666666668, 16.583333333333332, 16.583333333333332, 16.583333333333332, 19.166666666666668, 17.916666666666668]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [5.0, 45.0, 21.05263157894737]\n",
      "Inner_error_values are:[21.916666666666668, 21.833333333333332, 23.0, 24.25, 24.25, 24.25, 24.25, 29.333333333333332, 26.75, 24.166666666666668, 28.0, 28.0, 24.083333333333332, 24.083333333333332, 24.083333333333332, 22.833333333333332, 21.5, 25.5, 24.166666666666668, 25.5, 26.75, 23.0, 23.0, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75, 21.75]\n",
      "The index of optimal KNN value is: 10\n",
      "The optimal KNN value across inner CV folds is: 17\n",
      "Errors for each outer CV fold: [15.0, 35.0, 26.31578947368421]\n",
      "Errors for baseline outer fold[20.0, 25.0, 21.05263157894737]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[12.833333333333334, 13.916666666666666, 15.166666666666666, 11.416666666666666, 14.0, 13.916666666666666, 11.5, 14.0, 12.666666666666666, 13.916666666666666, 14.0, 10.166666666666666, 12.75, 10.166666666666666, 14.0, 13.916666666666666, 11.5, 10.166666666666666, 10.166666666666666]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 13\n",
      "Errors for each outer tc fold: [5.0, 45.0, 21.05263157894737, 21.05263157894737]\n",
      "Inner_error_values are:[21.75, 20.416666666666668, 17.833333333333332, 23.166666666666668, 23.083333333333332, 20.5, 23.083333333333332, 20.583333333333332, 19.333333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 19.333333333333332, 20.583333333333332, 19.333333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332, 20.583333333333332]\n",
      "The index of optimal KNN value is: 10\n",
      "The optimal KNN value across inner CV folds is: 3\n",
      "Errors for each outer CV fold: [15.0, 35.0, 26.31578947368421, 21.05263157894737]\n",
      "Errors for baseline outer fold[20.0, 25.0, 21.05263157894737, 26.31578947368421]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[20.583333333333336, 23.166666666666668, 23.166666666666668, 21.833333333333336, 21.833333333333336, 23.166666666666668, 21.833333333333336, 24.416666666666668, 20.5, 24.416666666666668, 23.083333333333336, 21.833333333333336, 20.5, 21.833333333333336, 21.833333333333336, 20.5, 21.833333333333336, 21.833333333333336, 21.833333333333336]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 10\n",
      "Errors for each outer tc fold: [5.0, 45.0, 21.05263157894737, 21.05263157894737, 31.57894736842105]\n",
      "Inner_error_values are:[20.333333333333332, 19.166666666666668, 19.166666666666668, 24.166666666666668, 23.0, 24.083333333333332, 26.75, 24.083333333333332, 25.416666666666668, 20.25, 19.083333333333332, 22.916666666666668, 23.0, 24.166666666666668, 22.833333333333332, 21.5, 21.5, 21.5, 20.166666666666668, 21.5, 21.5, 21.5, 21.5, 21.5, 21.5, 24.166666666666668, 24.166666666666668, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332, 22.833333333333332]\n",
      "The index of optimal KNN value is: 10\n",
      "The optimal KNN value across inner CV folds is: 11\n",
      "Errors for each outer CV fold: [15.0, 35.0, 26.31578947368421, 21.05263157894737, 26.31578947368421]\n",
      "Errors for baseline outer fold[20.0, 25.0, 21.05263157894737, 26.31578947368421, 15.789473684210526]\n"
     ]
    }
   ],
   "source": [
    "# Results from the 2-level cross-validation for dtc \n",
    "# Errors for each outer tc fold: [15.0, 30.0, 10.526315789473685, 10.526315789473685, 15.789473684210526]\n",
    "# The errors for the best performing models are: 10.526315789473685, 15.0\n",
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# dtc\n",
    "index_min_lst_dtc = []\n",
    "min_indices_dtc = []\n",
    "error_outer_dtc = [] # List for the errors in outer CV fold\n",
    "dict_inner_dtc = {}\n",
    "error_inner_dtc = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "classifier_lst_dtc = []\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner_dtc['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "# KNN\n",
    "index_min_lst_KNN = []\n",
    "min_indices_KNN = []\n",
    "error_outer_KNN = [] # List for the errors in outer CV fold\n",
    "dict_inner_KNN = {}\n",
    "error_inner_KNN = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "classifier_lst_KNN = []\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner_KNN['K_KNN_of_{0}'.format(value)] = []\n",
    "    \n",
    "# Baseline model\n",
    "error_baseline = []\n",
    "\n",
    "\n",
    "\n",
    "k=0\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "    # Decision tree classifier\n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst_dtc.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner_dtc['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "    \n",
    "    # KNN classifier\n",
    "            for count, value in enumerate(K_KNN):\n",
    "                dist=1\n",
    "                       \n",
    "                knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "                knclassifier.fit(X_train_inner, y_train_inner);\n",
    "                classifier_lst_KNN.append(knclassifier)\n",
    "            \n",
    "                y_KNN = knclassifier.predict(X_test_inner);\n",
    "                errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "                #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "                error_inner_KNN['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "        \n",
    "        \n",
    "        kk += 1\n",
    "    #dtc\n",
    "    # Find the dtc value with minimum average error value\n",
    "    for key in error_inner_dtc.keys():\n",
    "        index_min_lst_dtc.append(mean(error_inner_dtc[key]))\n",
    "        \n",
    "    print('Inner_error_values_ for dtc are:' + str(index_min_lst_dtc))\n",
    "    index_min_dtc = np.argmin(index_min_lst_dtc) #Find the index of the minimum error value\n",
    "    top_count_dtc = index_min_dtc\n",
    "    min_indices_dtc.append(index_min_dtc) \n",
    "        \n",
    "    index_min_lst_dtc = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_dtc.keys():\n",
    "        error_inner_dtc[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_tc = tc[top_count_dtc]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_dtc.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer_dtc))\n",
    "    \n",
    "    \n",
    "    # KNN\n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner_KNN.keys():\n",
    "        index_min_lst_KNN.append(mean(error_inner_KNN[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst_KNN))\n",
    "    index_min_KNN = np.argmin(index_min_lst_KNN) #Find the index of the minimum error value\n",
    "    top_count_KNN = index_min_KNN\n",
    "    min_indices_KNN.append(index_min_KNN) \n",
    "        \n",
    "    index_min_lst_KNN = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_KNN.keys():\n",
    "        error_inner_KNN[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count_KNN]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_KNN.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer_KNN))\n",
    " \n",
    "    \n",
    "    \n",
    "    # Fit baseline model\n",
    "            \n",
    "    y_baselinemodel = Baseline_model(y_train_outer, y_test_outer);\n",
    "    error_baseline_outer = 100*(y_baselinemodel!=y_test_outer).sum().astype(float)/len(y_test_outer)  \n",
    "    error_baseline.append(error_baseline_outer)\n",
    "    print('Errors for baseline outer fold'+str(error_baseline))\n",
    "\n",
    "error_dct = error_outer_dtc\n",
    "error_KNN = error_outer_KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.22680412371134\n",
      "24.22680412371134\n"
     ]
    }
   ],
   "source": [
    "# Final generalization error for DCT\n",
    "DTC_error = (len(y_test_outer)/N*np.mat(error_dct)).sum()\n",
    "print(DTC_error)\n",
    "# Final generalization error for KNN\n",
    "KNN_error = (len(y_test_outer)/N*np.mat(error_KNN)).sum()\n",
    "print(KNN_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer error dct is[5.0, 45.0, 21.05263157894737, 21.05263157894737, 31.57894736842105]\n",
      "Outer error of KNN is[15.0, 35.0, 26.31578947368421, 21.05263157894737, 26.31578947368421]\n",
      "Outer error of baseline_model is[20.0, 25.0, 21.05263157894737, 26.31578947368421, 15.789473684210526]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-validation error [%]')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1923db9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The two best performing models are from dct\n",
    "print('Outer error dct is' + str(error_dct))\n",
    "print('Outer error of KNN is' + str(error_KNN))\n",
    "print('Outer error of baseline_model is' + str(error_baseline))\n",
    "\n",
    "figure()\n",
    "boxplot([error_KNN, error_dct])\n",
    "xlabel('K-Nearest Neighbors   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 10\n",
      "CV-fold 2 of 10\n",
      "CV-fold 3 of 10\n",
      "CV-fold 4 of 10\n",
      "CV-fold 5 of 10\n",
      "CV-fold 6 of 10\n",
      "CV-fold 7 of 10\n",
      "CV-fold 8 of 10\n",
      "CV-fold 9 of 10\n",
      "CV-fold 10 of 10\n",
      "Model 1 and baseline model are significantly different.\n",
      "20.674506993717365\n",
      "48.43660411739375\n",
      "Baseline model and Model 2 are significantly different.\n",
      "31.97642597819574\n",
      "49.13468513291537\n",
      "Model 1 and Model 2 are not significantly different\n",
      "-1.86138429702791\n",
      "13.861384297027907\n"
     ]
    }
   ],
   "source": [
    "# The best performing classifiers are KNN with K = 2 and a dtc with tc=10\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "Error_base_line = np.empty((K,1))\n",
    "Error_model_1 = np.empty((K,1))\n",
    "Error_model_2 = np.empty((K,1))\n",
    "\n",
    "n_tested=0\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K))\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Fit and evaluate KNN\n",
    "    model1 = KNeighborsClassifier(n_neighbors=2, p=dist);\n",
    "    model1 = model1.fit(X_train, y_train)\n",
    "    y_model1 = model1.predict(X_test)\n",
    "    Error_model_1[k] = 100*(y_model1!=y_test).sum().astype(float)/len(y_test)\n",
    "    \n",
    "    # Fit and evaluate Decision Tree classifier\n",
    "    model2 = tree.DecisionTreeClassifier(criterion='gini', max_depth=10);\n",
    "    model2 = model2.fit(X_train, y_train.ravel())\n",
    "    y_model2 = model2.predict(X_test)\n",
    "    Error_model_2[k] = 100*(y_model2!=y_test).sum().astype(float)/len(y_test)  \n",
    "    \n",
    "    # Fit and evaluate baseline model classifier\n",
    "    y_baseline = Baseline_model(y_train, y_test);\n",
    "    Error_base_line[k] = 100*(y_baseline!=y_test).sum().astype(float)/len(y_test)\n",
    "  \n",
    "    k+=1\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Baseline model and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Baseline model and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gammel kode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3592b79c6b59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mzb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#nu = K-1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mzb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'K' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "Error_base_line = min(error_baseline)\n",
    "Error_model_1 = min(error_dct) # Gives the best performing model\n",
    "Error_model_2 = sorted(error_dct)[1] # Gives the second best performing model\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 2 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 2 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two level cross validation for KNN - Greta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.0, 15.0, 36.8421052631579, 15.789473684210526, 15.789473684210526]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = [1, 2, 3] # Change here for different nearest neighbour crossvalidation\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "        counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "        top_count = np.argmax(counts)\n",
    "        # Only use the count from the last iteration! \n",
    "        optimal_K = K_KNN[top_count]\n",
    "        \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4]\n",
      "The index of optimal KNN value is: 1\n",
      "The optimal KNN value across inner CV folds is: 2\n",
      "[15.0, 35.0, 10.526315789473685]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "[1, 2, 0, 13, 19, 7, 2, 3, 1, 1, 0, 33, 18, 3, 4, 0, 29, 24, 8, 13, 1, 12, 3, 13, 0]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "[15.0, 35.0, 10.526315789473685, 26.31578947368421, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "errorKNN_inner_GT=[]\n",
    "errorKNN_outer_GT = []\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = []\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = range(1,41)\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner_GT = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner_GT) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "    print(min_indices)\n",
    "    counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "    top_count = np.argmax(counts)\n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    # Only use the count from the last iteration! \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=1, p=dist);\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer_GT = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer_GT)\n",
    "    print(error_outer)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

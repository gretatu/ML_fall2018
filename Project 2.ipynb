{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this application is to solve relevant classification and regression problems for the prostate dataset for use in the project in 02450 Intro to Machine Learning\n",
    "\n",
    "Author: Naia Wright\n",
    "\n",
    "Reviewed by:  \n",
    "\n",
    "Last modified: 28/10/18, 09:39\n",
    "\n",
    "#### Change-log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "\n",
    "from matplotlib.pyplot import figure, boxplot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection, tree\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, bar, xlabel, ylabel, show, clim, xticks\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n",
    "\n",
    "from statistics import mean\n",
    "import graphviz\n",
    "from numpy import array\n",
    "from scipy import stats\n",
    "\n",
    "import os\n",
    "\n",
    "import neurolab as nl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a method for importing a spread_sheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, sheet):\n",
    "    \"\"\"\n",
    "    Method for importing data from a spreadsheet.\n",
    "\n",
    "    :param path: full path to the spreadsheet to load\n",
    "    :param sheet: name of the sheet in the workbook that is loaded\n",
    "    :return: pandas dataFrame with imported data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    out = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path and sheet name in the prostate workbook\n",
    "base_dir = os.getcwd()\n",
    "filePath = base_dir + '/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/PeterBakke/Documents/git/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/Greta/Documents/Github/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/narisa/Documents/GitHub/ML_fall2018/Data/Prostate.xlsx'\n",
    "sheet = 'Sheet1'\n",
    "\n",
    "seed = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prostate data into dataFrame\n",
    "myData = DataLoader(path=filePath, sheet=sheet)\n",
    "\n",
    "# delete irrelevant columns\n",
    "del myData['ID']\n",
    "del myData['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol', 'lWeight', 'Age', 'lBPH', 'SVI', 'lCP', 'Gleason', 'pgg45', 'lPSA']\n"
     ]
    }
   ],
   "source": [
    "# Extract class names \n",
    "attributeNames = list(myData.columns.values)\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "X = myData.values\n",
    "\n",
    "# Compute values of N (observations) and M (features)\n",
    "M = len(attributeNames)\n",
    "N = X.shape[0]\n",
    "\n",
    "print(attributeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting and deleting PGG45 and Gleason from X, as well as SVI (to not normalize SVI)\n",
    "X_orig = np.copy(X)\n",
    "\n",
    "gleason = X_orig[:,6]\n",
    "pgg = X_orig[:,7]\n",
    "svi = X_orig[:,4]\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBS - only run this once\n",
    "X = np.delete(X,6,1) # Deletes Gleason\n",
    "X = np.delete(X,6,1) # Deletes PGG\n",
    "X = np.delete(X,4,1) # Deletes SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z score all other variables \n",
    "X_z = zscore(X)\n",
    "# print(X_z)\n",
    "\n",
    "# Current order: lCavol, lWeight, Age, lBPH, lCP, lPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One out of K coding for PGG and Gleason\n",
    "\n",
    "from categoric2numeric import *\n",
    "\n",
    "[X_Gleason, attribute_names_Gleason]=categoric2numeric(gleason)\n",
    "[X_PGG45, attribute_names_PGG45]=categoric2numeric(pgg)\n",
    "\n",
    "#print(X_Gleason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 1)\n",
      "(97, 11)\n",
      "[-1.58702059 -2.20015441  1.36823439 -1.03002898 -0.86765522 -2.29971238\n",
      "  0.          1.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Add one out of K coded Gleason and PGG columns, as well as SVI \n",
    "svi = np.reshape(svi,[97,1])\n",
    "print(svi.shape)\n",
    "# X_k = np.concatenate((X,X_Gleason,X_PGG45,svi),axis=1)\n",
    "X_k = np.concatenate((X_z,X_Gleason,svi),axis=1)\n",
    "\n",
    "print(X_k.shape)\n",
    "print(X_k[2])\n",
    "\n",
    "# Order: lCavol, lWeight, Age, lBPH, lCP, lPSA, Gleason (4 columns), (PGG (19 columns)), SVI (1 column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove attribute 10 (SVI) and Gleason from X\n",
    "X_classification = X_k[:,[0,1,2,3,4,5,6,7,8,9]]\n",
    "\n",
    "# Use attribute 5 (SVI) as y\n",
    "y_classification = X_k[:,10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "N, M = X_classification.shape\n",
    "\n",
    "print(N)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract class names and encode with integers (dict)\n",
    "\n",
    "#classLabels = myData['Gleason'].values.tolist()\n",
    "#classNames = sorted(set(classLabels))\n",
    "#classDict = dict(zip(classNames, range(4)))\n",
    "\n",
    "#del myData['Gleason']\n",
    "\n",
    "#attributeNames = list(myData.columns.values)\n",
    "\n",
    "#print(attributeNames)\n",
    "#print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector y, convert to NumPy array\n",
    "#y = np.asarray([classDict[value] for value in classLabels])\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "#X = myData.values\n",
    "\n",
    "# Compute values of N, M and C\n",
    "#N = len(y)\n",
    "#M = len(attributeNames)\n",
    "#C = len(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data with mean and std\n",
    "#Y = (X - np.ones((N,1))*X.mean(axis=0)) / X.std(axis=0)\n",
    "print(y_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCavol' 'lWeight' 'Age' 'lBPH' 'lCP' 'lPSA' 'Gleason 1' 'Gleason 2'\n",
      " 'Gleason 3' 'Gleason 4']\n"
     ]
    }
   ],
   "source": [
    "# Remove attribute 5 (SVI) from X\n",
    "#X_classification = Y[:,[0,1,2,3,5,6,7,8]]\n",
    "#print(X_classification)\n",
    "# Use attribute 5 (SVI) as y\n",
    "#y_classification = X[:,4]\n",
    "#print(y_classification)\n",
    "# Remove attribute 5 (SVI) from attribute names\n",
    "\n",
    "#lCavol, lWeight, Age, lBPH, lCP, lPSA, Gleason (4 columns), (PGG (19 columns)), SVI (1 column)\n",
    "\n",
    "attributeNames_classification = np.array(['lCavol', 'lWeight', 'Age', 'lBPH', 'lCP', 'lPSA', 'Gleason 1', 'Gleason 2', 'Gleason 3', 'Gleason 4'])\n",
    "print(attributeNames_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for KNN - Naia 2018-11-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.75, 18.166666666666668, 14.25, 16.833333333333332, 14.25, 15.5, 11.666666666666668, 14.166666666666668, 12.916666666666666, 14.166666666666668, 14.166666666666668, 14.083333333333334, 12.916666666666668, 11.583333333333334, 11.583333333333334, 11.583333333333334, 11.583333333333334, 12.833333333333334, 11.583333333333334, 15.416666666666668, 14.166666666666668, 15.416666666666668, 12.833333333333334, 19.333333333333332, 19.333333333333332, 18.0, 18.083333333333332, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336]\n",
      "The index of optimal KNN value is: 13\n",
      "The optimal KNN value across inner CV folds is: 14\n",
      "Errors for each outer CV fold: [20.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[9.166666666666668, 16.833333333333332, 14.416666666666668, 12.916666666666666, 14.333333333333334, 15.583333333333334, 14.416666666666668, 14.416666666666668, 15.666666666666668, 16.916666666666668, 15.583333333333334, 16.75, 13.0, 11.666666666666668, 11.666666666666668, 14.25, 13.083333333333334, 11.75, 11.75, 15.5, 14.25, 18.166666666666668, 16.916666666666668, 20.666666666666668, 19.333333333333332, 24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 23.166666666666668, 24.5, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "Errors for each outer CV fold: [20.0, 20.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[20.5, 13.916666666666666, 16.583333333333332, 16.416666666666668, 13.833333333333334, 15.166666666666666, 14.0, 15.25, 15.25, 15.25, 15.333333333333334, 15.25, 12.75, 16.583333333333332, 15.333333333333334, 20.416666666666668, 15.25, 21.583333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332]\n",
      "The index of optimal KNN value is: 12\n",
      "The optimal KNN value across inner CV folds is: 13\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[14.0, 16.666666666666668, 14.25, 11.583333333333334, 12.833333333333334, 11.583333333333334, 12.833333333333334, 15.416666666666666, 11.583333333333334, 12.833333333333334, 15.416666666666666, 14.166666666666666, 12.833333333333334, 15.416666666666666, 15.416666666666666, 16.666666666666668, 15.416666666666666, 19.166666666666668, 16.666666666666668, 19.166666666666668, 17.916666666666668, 20.333333333333332, 21.666666666666668, 21.583333333333332, 21.583333333333332, 22.916666666666668, 22.916666666666668, 22.916666666666668, 24.25, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[16.5, 13.916666666666666, 16.5, 11.416666666666666, 14.0, 15.25, 12.666666666666666, 16.5, 19.166666666666668, 19.166666666666668, 19.166666666666668, 17.833333333333332, 16.583333333333332, 16.5, 17.75, 16.5, 13.833333333333334, 16.5, 15.166666666666666, 16.5, 15.166666666666666, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685, 15.789473684210526, 26.31578947368421]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True, random_state=seed)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=2 #euclidean_distance\n",
    "                       \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "error_KNN = error_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two level cross validation for decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[13.0, 14.333333333333334, 16.916666666666668, 14.333333333333334, 14.416666666666668, 14.416666666666668, 13.083333333333334, 15.583333333333334, 16.916666666666668, 14.333333333333334, 16.916666666666668, 18.166666666666668, 16.916666666666668, 14.416666666666668, 14.416666666666668, 15.583333333333334, 14.416666666666668, 14.416666666666668]\n",
      "The index of optimal tc value is: 0\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[16.916666666666668, 13.083333333333334, 11.666666666666668, 9.083333333333334, 12.916666666666668, 10.416666666666668, 12.916666666666668, 10.416666666666668, 14.25, 10.416666666666668, 10.416666666666668, 11.666666666666668, 10.416666666666668, 11.666666666666668, 12.916666666666668, 12.916666666666668, 12.916666666666668, 10.416666666666668]\n",
      "The index of optimal tc value is: 3\n",
      "The optimal tc value across inner CV folds is: 5\n",
      "Errors for each outer tc fold: [15.0, 30.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[15.333333333333334, 21.666666666666668, 17.833333333333332, 15.25, 19.0, 16.5, 16.5, 19.0, 15.25, 15.25, 20.333333333333332, 17.75, 17.75, 16.5, 15.25, 15.25, 16.583333333333332, 15.25]\n",
      "The index of optimal tc value is: 3\n",
      "The optimal tc value across inner CV folds is: 5\n",
      "Errors for each outer tc fold: [15.0, 30.0, 5.2631578947368425]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[20.666666666666668, 20.583333333333336, 15.5, 12.75, 18.0, 20.583333333333336, 15.333333333333334, 16.666666666666668, 19.416666666666668, 21.916666666666668, 12.75, 20.583333333333332, 12.75, 14.083333333333334, 16.583333333333332, 16.583333333333332, 18.0, 16.583333333333332]\n",
      "The index of optimal tc value is: 3\n",
      "The optimal tc value across inner CV folds is: 5\n",
      "Errors for each outer tc fold: [15.0, 30.0, 5.2631578947368425, 21.05263157894737]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values are:[12.75, 12.75, 15.333333333333334, 14.0, 14.0, 14.0, 15.25, 15.333333333333334, 15.333333333333334, 14.0, 14.0, 14.0, 14.0, 15.333333333333334, 16.583333333333332, 15.25, 15.333333333333334, 15.25]\n",
      "The index of optimal tc value is: 0\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0, 30.0, 5.2631578947368425, 21.05263157894737, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 20, 1)\n",
    "print(tc)\n",
    "\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True, random_state=seed)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_tc = tc[top_count]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer))\n",
    "\n",
    "error_dct = error_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-validation error [%]')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2872f9c5400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure()\n",
    "boxplot([error_KNN, error_dct])\n",
    "xlabel('K-Nearest Neighbors   vs.   Decision Tree')\n",
    "ylabel('Cross-validation error [%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method selected: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Re-estimate of the model on all data for a maximum depth of 5\n",
    "\n",
    "# Fit decision tree classifier, Gini split criterion, maximum depth of 5 on all data\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=5) \n",
    "dtc.fit(X_classification, y_classification.ravel())\n",
    "\n",
    "# New data object\n",
    "new_data = np.array([2, 2, 4, -1, -1, -3, 0, 0, 0, 1]).reshape(1,-1) # Gives 0 - No SVI\n",
    "#new_data = np.array([2, 2, 4, -1, 2, -3, 0, 0, 0, 1]).reshape(1,-1) # Gives 1 - Yes SVI\n",
    "\n",
    "# Evalulate the decision tree for a new data object\n",
    "new_data_class = dtc.predict(new_data)[0]\n",
    "print(new_data_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  4 -1 -1 -3  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCavol' 'lWeight' 'Age' 'lBPH' 'lCP' 'lPSA' 'Gleason 1' 'Gleason 2'\n",
      " 'Gleason 3' 'Gleason 4']\n"
     ]
    }
   ],
   "source": [
    "print(attributeNames_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"623pt\" height=\"581pt\"\r\n",
       " viewBox=\"0.00 0.00 622.50 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-577 618.5,-577 618.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"439.5,-573 335.5,-573 335.5,-505 439.5,-505 439.5,-573\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-557.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCP &lt;= 1.416</text>\r\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-542.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.339</text>\r\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-527.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 97</text>\r\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-512.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [76, 21]</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379,-469 278,-469 278,-401 379,-401 379,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 0.448</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.191</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 84</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [75, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.344,-504.884C363.398,-496.332 358.008,-487.013 352.836,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.798,-476.203 347.761,-469.299 349.739,-479.708 355.798,-476.203\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"341.31\" y=\"-489.753\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"498,-469 397,-469 397,-401 498,-401 498,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCavol &lt;= 1.05</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.142</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 12]</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>0&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406.98,-504.884C412.01,-496.332 417.492,-487.013 422.752,-478.072\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.859,-479.693 427.912,-469.299 419.825,-476.144 425.859,-479.693\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"434.186\" y=\"-489.799\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"259.5,-357.5 161.5,-357.5 161.5,-304.5 259.5,-304.5 259.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 66</text>\r\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [66, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M290.189,-400.884C276.575,-389.116 261.279,-375.894 247.755,-364.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"249.877,-361.412 240.023,-357.52 245.3,-366.707 249.877,-361.412\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"379,-365 278,-365 278,-297 379,-297 379,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lBPH &lt;= 1.038</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 18</text>\r\n",
       "<text text-anchor=\"middle\" x=\"328.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [9, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.5,-400.884C328.5,-392.778 328.5,-383.982 328.5,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"332,-375.299 328.5,-365.299 325,-375.299 332,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"267,-261 160,-261 160,-193 267,-193 267,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lCavol &lt;= 1.105</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.426</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"213.5\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [4, 9]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M291.163,-296.884C280.819,-287.709 269.478,-277.65 258.736,-268.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.847,-265.317 251.043,-261.299 256.202,-270.553 260.847,-265.317\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"376,-253.5 285,-253.5 285,-200.5 376,-200.5 376,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"330.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"330.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"330.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [5, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>3&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329.149,-296.884C329.359,-286.216 329.591,-274.352 329.804,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333.303,-263.587 330,-253.52 326.304,-263.449 333.303,-263.587\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"209,-157 90,-157 90,-89 209,-89 209,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lWeight &lt;= &#45;1.115</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.219</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 8</text>\r\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.721,-192.884C187.3,-184.243 181.387,-174.819 175.723,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.673,-163.91 170.394,-157.299 172.744,-167.63 178.673,-163.91\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"328,-157 227,-157 227,-89 328,-89 328,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 1.506</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.48</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"277.5\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>4&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.279,-192.884C239.7,-184.243 245.613,-174.819 251.277,-165.793\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.256,-167.63 256.606,-157.299 248.327,-163.91 254.256,-167.63\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"91,-53 0,-53 0,-0 91,-0 91,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"45.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>5&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.126,-88.9485C102.857,-79.6175 91.6916,-69.4722 81.4478,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.5788,-57.3713 73.824,-53.2367 78.8713,-62.5521 83.5788,-57.3713\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"200,-53 109,-53 109,-0 200,-0 200,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 7</text>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 7]</text>\r\n",
       "</g>\r\n",
       "<!-- 5&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>5&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.249,-88.9485C151.684,-80.7153 152.154,-71.848 152.596,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.105,-63.4077 153.138,-53.2367 149.115,-63.0378 156.105,-63.4077\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"314,-53 223,-53 223,-0 314,-0 314,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"268.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [3, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>8&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M274.352,-88.9485C273.559,-80.6238 272.705,-71.6509 271.9,-63.2027\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.384,-62.8598 270.951,-53.2367 268.415,-63.5235 275.384,-62.8598\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"423,-53 332,-53 332,-0 423,-0 423,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"377.5\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 8&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>8&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M312.475,-88.9485C322.349,-79.6175 333.085,-69.4722 342.935,-60.1641\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345.401,-62.649 350.265,-53.2367 340.593,-57.5613 345.401,-62.649\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"498,-365 397,-365 397,-297 498,-297 498,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">lPSA &lt;= 0.634</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"447.5\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M447.5,-400.884C447.5,-392.778 447.5,-383.982 447.5,-375.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"451,-375.299 447.5,-365.299 444,-375.299 451,-375.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"614.5,-357.5 516.5,-357.5 516.5,-304.5 614.5,-304.5 614.5,-357.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"565.5\" y=\"-342.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"565.5\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 10</text>\r\n",
       "<text text-anchor=\"middle\" x=\"565.5\" y=\"-312.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 10]</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>12&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M485.811,-400.884C499.425,-389.116 514.721,-375.894 528.245,-364.203\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"530.7,-366.707 535.977,-357.52 526.123,-361.412 530.7,-366.707\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"490,-253.5 399,-253.5 399,-200.5 490,-200.5 490,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"444.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"444.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"444.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [0, 2]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M446.526,-296.884C446.212,-286.216 445.863,-274.352 445.545,-263.519\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"449.043,-263.413 445.251,-253.52 442.046,-263.619 449.043,-263.413\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"599,-253.5 508,-253.5 508,-200.5 599,-200.5 599,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"553.5\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"553.5\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"553.5\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = [1, 0]</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M481.915,-296.884C494.03,-285.226 507.628,-272.141 519.693,-260.532\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"522.2,-262.976 526.979,-253.52 517.347,-257.932 522.2,-262.976\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x2872fd92240>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export tree graph for visualization purposes:\n",
    "# (note: you can use i.e. Graphviz application to visualize the file)\n",
    "out = tree.export_graphviz(dtc, out_file='tree_gini.gvz', feature_names=attributeNames_classification)\n",
    "#graphviz.render('dot','png','tree_gini',quiet=False)\n",
    "src=graphviz.Source.from_file('tree_gini.gvz')\n",
    "## Comment in to automatically open pdf\n",
    "## Note. If you get an error (e.g. exit status 1), try closing the pdf file/viewer\n",
    "#src.render('../tree_gini', view=True)\n",
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN For Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for neural network classifier\n",
    "n_hidden_units = [2,4,6,8,10,15]      # number of hidden units\n",
    "n_train = 6             # number of networks trained in each k-fold\n",
    "learning_goal = 0.0001     # stop criterion 1 (train mse to be reached)\n",
    "max_epochs = 512         # stop criterion 2 (max epochs in training)\n",
    "show_error_freq = 100     # frequency of training status updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold crossvalidation\n",
    "K = 5                   # only three folds to speed up this example\n",
    "CV = model_selection.KFold(K,shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crossvalidation fold: 1/5\n",
      "Training network 1/6...\n",
      "Training network 2/6...\n",
      "Training network 3/6...\n",
      "Training network 4/6...\n",
      "Training network 5/6...\n",
      "Training network 6/6...\n",
      "Best train error: 2.38289712506086...\n",
      "Optimal number of hidden neurons: 8...\n",
      "5.0\n",
      "\n",
      "Crossvalidation fold: 2/5\n",
      "Training network 1/6...\n",
      "Training network 2/6...\n",
      "Training network 3/6...\n",
      "Training network 4/6...\n",
      "Training network 5/6...\n",
      "Training network 6/6...\n",
      "Best train error: 2.2451885869100288...\n",
      "Optimal number of hidden neurons: 8...\n",
      "-5.0\n",
      "\n",
      "Crossvalidation fold: 3/5\n",
      "Training network 1/6...\n",
      "Training network 2/6...\n",
      "Training network 3/6...\n",
      "Training network 4/6...\n",
      "Training network 5/6...\n",
      "Training network 6/6...\n",
      "Best train error: 2.619406190614707...\n",
      "Optimal number of hidden neurons: 4...\n",
      "-15.789473684210526\n",
      "\n",
      "Crossvalidation fold: 4/5\n",
      "Training network 1/6...\n",
      "Training network 2/6...\n",
      "Training network 3/6...\n",
      "Training network 4/6...\n",
      "Training network 5/6...\n",
      "Training network 6/6...\n",
      "Best train error: 3.3238834743615366...\n",
      "Optimal number of hidden neurons: 15...\n",
      "5.2631578947368425\n",
      "\n",
      "Crossvalidation fold: 5/5\n",
      "Training network 1/6...\n",
      "Training network 2/6...\n",
      "Training network 3/6...\n",
      "Training network 4/6...\n",
      "Training network 5/6...\n",
      "Training network 6/6...\n",
      "Best train error: 2.6317557084833187...\n",
      "Optimal number of hidden neurons: 8...\n",
      "-21.05263157894737\n"
     ]
    }
   ],
   "source": [
    "# Variable for classification error\n",
    "errors = np.zeros(K)*np.nan\n",
    "gen_error = np.zeros(K)*np.nan\n",
    "error_hist = np.zeros((max_epochs,K))*np.nan\n",
    "bestnet = list()\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X_classification,y_classification):\n",
    "    print('\\nCrossvalidation fold: {0}/{1}'.format(k+1,K))    \n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X_classification[train_index,:]\n",
    "    y_train = y_classification[train_index]\n",
    "    X_test = X_classification[test_index,:]\n",
    "    y_test = y_classification[test_index]\n",
    "    \n",
    "    best_train_error = np.inf\n",
    "    for i in range(n_train):\n",
    "        print('Training network {0}/{1}...'.format(i+1,n_train))\n",
    "        # Create randomly initialized network with 2 layers\n",
    "        ann = nl.net.newff([[-10,10]]*M, [n_hidden_units[i], 1], [nl.trans.LogSig(),nl.trans.LogSig()])\n",
    "        if i==0:\n",
    "            bestnet.append(ann)\n",
    "        # train network\n",
    "        train_error = ann.train(X_train, y_train.reshape(-1,1), goal=learning_goal, epochs=max_epochs, show=show_error_freq, rr=0.3)\n",
    "        \n",
    "        if train_error[-1]<best_train_error:\n",
    "            bestnet[k]=ann\n",
    "            best_train_error = train_error[-1]\n",
    "            error_hist[range(len(train_error)),k] = train_error\n",
    "            best_no_neurons = n_hidden_units[i]\n",
    "\n",
    "    print('Best train error: {0}...'.format(best_train_error))\n",
    "    print('Optimal number of hidden neurons: {0}...'.format(best_no_neurons))\n",
    "    y_est = bestnet[k].sim(X_test).squeeze()\n",
    "    y_est = (y_est>.5).astype(int)\n",
    "    errors[k] = np.power(y_est-y_test,2).sum().astype(float)/y_test.shape[0]\n",
    "    #errors[k] = 100*(y_est!=y_test).sum().astype(float)/y_test.shape[0]\n",
    "    gen_error[k] = 100 * (y_est-y_test).sum().astype(float)/y_test.shape[0]\n",
    "    #errors[k] = - y_test * np.log(y_est) - (1 - y_test) * np.log (1 - y_est)\n",
    "    print(gen_error[k])\n",
    "    k+=1\n",
    "    #break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-square error: 0.14421052631578948\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2872fd98b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2872fa8b3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the average least squares error\n",
    "print('Mean-square error: {0}'.format(np.mean(errors)))\n",
    "\n",
    "figure(figsize=(6,7));\n",
    "subplot(2,1,1); bar(range(0,K),errors); title('Mean-square errors');\n",
    "subplot(2,1,2); plot(error_hist); title('Training error as function of BP iterations');\n",
    "figure(figsize=(6,7));\n",
    "subplot(2,1,1); plot(y_est); plot(y_test); title('Last CV-fold: est_y vs. test_y'); \n",
    "subplot(2,1,2); plot((y_est-y_test)); title('Last CV-fold: prediction error (est_y-test_y)'); \n",
    "show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# zero rule algorithm for classification\n",
    "def Baseline_model(y_train, y_test):\n",
    "    prediction = stats.mode(y_train)[0]\n",
    "    predicted = [int(prediction) for i in range(len(y_test))]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-level-cross validation for dtc, KNN and baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[13.0, 16.833333333333332, 15.583333333333334, 14.416666666666668, 19.416666666666668, 14.416666666666668, 15.666666666666668, 18.166666666666668, 14.333333333333334, 14.416666666666668, 16.916666666666668, 14.416666666666668, 16.916666666666668, 15.583333333333334, 14.416666666666668, 13.083333333333334, 13.083333333333334, 14.416666666666668, 18.166666666666668]\n",
      "The index of optimal tc value is: 0\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0]\n",
      "Inner_error_values are:[15.75, 18.166666666666668, 14.25, 16.833333333333332, 14.25, 15.5, 11.666666666666668, 14.166666666666668, 12.916666666666666, 14.166666666666668, 14.166666666666668, 14.083333333333334, 12.916666666666668, 11.583333333333334, 11.583333333333334, 11.583333333333334, 11.583333333333334, 12.833333333333334, 11.583333333333334, 15.416666666666668, 14.166666666666668, 15.416666666666668, 12.833333333333334, 19.333333333333332, 19.333333333333332, 18.0, 18.083333333333332, 21.916666666666668, 21.916666666666668, 21.916666666666668, 21.916666666666668, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336, 24.583333333333336]\n",
      "The index of optimal KNN value is: 13\n",
      "The optimal KNN value across inner CV folds is: 14\n",
      "Errors for each outer CV fold: [20.0]\n",
      "Inner_error_values are:[[10.526315789473685], [], [], [15.789473684210526, 15.789473684210526], [], [10.526315789473685, 10.526315789473685]]\n",
      "The index of optimal ANN value is: 1\n",
      "The optimal number of neurons in ANN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [10.526315789473685]\n",
      "Errors for baseline outer fold[10.0]\n",
      "CV-fold 2 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[16.916666666666668, 13.083333333333334, 11.75, 9.083333333333334, 10.416666666666668, 12.916666666666668, 11.75, 10.416666666666668, 11.666666666666668, 10.416666666666668, 11.583333333333334, 10.416666666666668, 9.083333333333334, 11.666666666666668, 10.416666666666668, 11.666666666666668, 11.666666666666668, 10.416666666666668, 10.416666666666668]\n",
      "The index of optimal tc value is: 3\n",
      "The optimal tc value across inner CV folds is: 5\n",
      "Errors for each outer tc fold: [15.0, 25.0]\n",
      "Inner_error_values are:[9.166666666666668, 16.833333333333332, 14.416666666666668, 12.916666666666666, 14.333333333333334, 15.583333333333334, 14.416666666666668, 14.416666666666668, 15.666666666666668, 16.916666666666668, 15.583333333333334, 16.75, 13.0, 11.666666666666668, 11.666666666666668, 14.25, 13.083333333333334, 11.75, 11.75, 15.5, 14.25, 18.166666666666668, 16.916666666666668, 20.666666666666668, 19.333333333333332, 24.5, 24.5, 24.5, 24.5, 24.5, 24.5, 23.166666666666668, 24.5, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668, 23.166666666666668]\n",
      "The index of optimal KNN value is: 0\n",
      "The optimal KNN value across inner CV folds is: 1\n",
      "Errors for each outer CV fold: [20.0, 20.0]\n",
      "Inner_error_values are:[[], [], [], [21.05263157894737, 21.05263157894737, 15.789473684210526], [5.2631578947368425], [10.526315789473685]]\n",
      "The index of optimal ANN value is: 0\n",
      "The optimal number of neurons in ANN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.526315789473685, 15.789473684210526]\n",
      "Errors for baseline outer fold[10.0, 15.0]\n",
      "CV-fold 3 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[15.333333333333334, 20.416666666666668, 17.833333333333332, 15.25, 19.0, 20.333333333333332, 15.25, 15.25, 16.5, 15.25, 17.75, 15.25, 15.25, 15.25, 17.75, 16.5, 16.5, 20.333333333333332, 17.75]\n",
      "The index of optimal tc value is: 3\n",
      "The optimal tc value across inner CV folds is: 5\n",
      "Errors for each outer tc fold: [15.0, 25.0, 5.2631578947368425]\n",
      "Inner_error_values are:[20.5, 13.916666666666666, 16.583333333333332, 16.416666666666668, 13.833333333333334, 15.166666666666666, 14.0, 15.25, 15.25, 15.25, 15.333333333333334, 15.25, 12.75, 16.583333333333332, 15.333333333333334, 20.416666666666668, 15.25, 21.583333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 21.666666666666668, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332, 20.333333333333332]\n",
      "The index of optimal KNN value is: 12\n",
      "The optimal KNN value across inner CV folds is: 13\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685]\n",
      "Inner_error_values are:[[], [10.526315789473685], [], [21.05263157894737, 10.526315789473685], [], [15.789473684210526, 21.05263157894737]]\n",
      "The index of optimal ANN value is: 0\n",
      "The optimal number of neurons in ANN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.526315789473685, 15.789473684210526, 21.05263157894737]\n",
      "Errors for baseline outer fold[10.0, 15.0, 26.31578947368421]\n",
      "CV-fold 4 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[22.0, 19.333333333333336, 15.333333333333334, 18.0, 19.416666666666668, 18.166666666666668, 16.666666666666668, 21.916666666666668, 20.583333333333332, 19.333333333333332, 12.75, 18.0, 17.916666666666668, 20.75, 18.0, 18.0, 20.666666666666668, 16.583333333333332, 15.416666666666668]\n",
      "The index of optimal tc value is: 10\n",
      "The optimal tc value across inner CV folds is: 12\n",
      "Errors for each outer tc fold: [15.0, 25.0, 5.2631578947368425, 15.789473684210526]\n",
      "Inner_error_values are:[14.0, 16.666666666666668, 14.25, 11.583333333333334, 12.833333333333334, 11.583333333333334, 12.833333333333334, 15.416666666666666, 11.583333333333334, 12.833333333333334, 15.416666666666666, 14.166666666666666, 12.833333333333334, 15.416666666666666, 15.416666666666666, 16.666666666666668, 15.416666666666666, 19.166666666666668, 16.666666666666668, 19.166666666666668, 17.916666666666668, 20.333333333333332, 21.666666666666668, 21.583333333333332, 21.583333333333332, 22.916666666666668, 22.916666666666668, 22.916666666666668, 24.25, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668, 22.916666666666668]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685, 15.789473684210526]\n",
      "Inner_error_values are:[[], [10.526315789473685], [15.789473684210526], [10.526315789473685], [21.05263157894737], [21.05263157894737]]\n",
      "The index of optimal ANN value is: 0\n",
      "The optimal number of neurons in ANN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.526315789473685, 15.789473684210526, 21.05263157894737, 10.526315789473685]\n",
      "Errors for baseline outer fold[10.0, 15.0, 26.31578947368421, 15.789473684210526]\n",
      "CV-fold 5 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "Inner CV-fold 2 of 5\n",
      "Inner CV-fold 3 of 5\n",
      "Inner CV-fold 4 of 5\n",
      "Inner CV-fold 5 of 5\n",
      "Inner_error_values_ for dtc are:[12.75, 12.75, 14.0, 15.25, 15.333333333333334, 14.0, 14.0, 14.0, 15.333333333333334, 15.25, 14.0, 14.0, 14.0, 16.583333333333332, 14.0, 14.0, 14.0, 14.0, 15.333333333333334]\n",
      "The index of optimal tc value is: 0\n",
      "The optimal tc value across inner CV folds is: 2\n",
      "Errors for each outer tc fold: [15.0, 25.0, 5.2631578947368425, 15.789473684210526, 21.05263157894737]\n",
      "Inner_error_values are:[16.5, 13.916666666666666, 16.5, 11.416666666666666, 14.0, 15.25, 12.666666666666666, 16.5, 19.166666666666668, 19.166666666666668, 19.166666666666668, 17.833333333333332, 16.583333333333332, 16.5, 17.75, 16.5, 13.833333333333334, 16.5, 15.166666666666666, 16.5, 15.166666666666666, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5, 16.5]\n",
      "The index of optimal KNN value is: 3\n",
      "The optimal KNN value across inner CV folds is: 4\n",
      "Errors for each outer CV fold: [20.0, 20.0, 10.526315789473685, 15.789473684210526, 26.31578947368421]\n",
      "Inner_error_values are:[[], [], [21.05263157894737, 10.526315789473685], [21.05263157894737], [21.05263157894737], [21.05263157894737]]\n",
      "The index of optimal ANN value is: 0\n",
      "The optimal number of neurons in ANN value across inner CV folds is: 2\n",
      "Errors for each outer CV fold: [10.526315789473685, 15.789473684210526, 21.05263157894737, 10.526315789473685, 21.05263157894737]\n",
      "Errors for baseline outer fold[10.0, 15.0, 26.31578947368421, 15.789473684210526, 42.10526315789474]\n"
     ]
    }
   ],
   "source": [
    "# Results from the 2-level cross-validation for dtc \n",
    "# Errors for each outer tc fold: [15.0, 30.0, 10.526315789473685, 10.526315789473685, 15.789473684210526]\n",
    "# The errors for the best performing models are: 10.526315789473685, 15.0\n",
    "## Crossvalidation for decision trees\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# dtc\n",
    "index_min_lst_dtc = []\n",
    "min_indices_dtc = []\n",
    "error_outer_dtc = [] # List for the errors in outer CV fold\n",
    "dict_inner_dtc = {}\n",
    "error_inner_dtc = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "# Tree complexity parameter - constraint on maximum depth\n",
    "tc = np.arange(2, 21, 1)\n",
    "classifier_lst_dtc = []\n",
    "\n",
    "for count, value in enumerate(tc):\n",
    "    error_inner_dtc['tc_of_{0}'.format(value)] = []\n",
    "\n",
    "# KNN\n",
    "index_min_lst_KNN = []\n",
    "min_indices_KNN = []\n",
    "error_outer_KNN = [] # List for the errors in outer CV fold\n",
    "dict_inner_KNN = {}\n",
    "error_inner_KNN = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "K_KNN = range(1,41) # Change here for different nearest neighbour crossvalidation - test of K=1-40\n",
    "classifier_lst_KNN = []\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner_KNN['K_KNN_of_{0}'.format(value)] = []\n",
    "    \n",
    "\n",
    "# ANN\n",
    "ANN = []\n",
    "index_min_lst_ANN = []\n",
    "min_indices_ANN = []\n",
    "error_outer_ANN = [] # List for the errors in outer CV fold\n",
    "dict_inner_ANN = {}\n",
    "error_inner_ANN = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "n_hidden_units = [2,4,6,8,10,15]      # number of hidden units\n",
    "classifier_lst_ANN = []\n",
    "\n",
    "\n",
    "\n",
    "for count, value in enumerate(n_hidden_units):\n",
    "    error_inner_ANN['NO_HIDDEN_of_{0}'.format(value)] = []\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Baseline model\n",
    "error_baseline = []\n",
    "\n",
    "\n",
    "\n",
    "k=0\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True, random_state=seed)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "    \n",
    "    \n",
    "    # ANN Classifier\n",
    "        best_train_error = np.inf\n",
    "        for i in range(n_train):\n",
    "            #print('Training network {0}/{1}...'.format(i+1,n_train))\n",
    "            # Create randomly initialized network with 2 layers\n",
    "            ann = nl.net.newff([[-10,10]]*M, [n_hidden_units[i], 1], [nl.trans.LogSig(),nl.trans.LogSig()])\n",
    "            if i==0:\n",
    "                bestnet.append(ann)\n",
    "            # train network\n",
    "            train_error = ann.train(X_train, y_train.reshape(-1,1), goal=learning_goal, epochs=max_epochs, show=show_error_freq, rr=0.1)\n",
    "            #print(train_error)\n",
    "            \n",
    "            \n",
    "            if train_error[-1]<best_train_error:\n",
    "                bestnet[k]=ann\n",
    "                best_train_error = train_error[-1]\n",
    "                error_hist[range(len(train_error)),kk] = train_error\n",
    "                best_no_neurons = n_hidden_units[i]\n",
    "                #print(1)\n",
    "        #print('Best train error: {0}...'.format(best_train_error))\n",
    "        #print('Optimal number of hidden neurons: {0}...'.format(best_no_neurons))\n",
    "        y_est = bestnet[k].sim(X_test).squeeze()\n",
    "        y_est = (y_est>.5).astype(int)\n",
    "        #print(2)\n",
    "        errors[kk] = np.power(y_est-y_test,2).sum().astype(float)/y_test.shape[0]\n",
    "        #errors[kk] = 100*(y_est!=y_test).sum().astype(float)/y_test.shape[0]\n",
    "        gen_error[kk] = 100 * (y_est-y_test).sum().astype(float)/y_test.shape[0]\n",
    "        #print(gen_error[kk])\n",
    "        #errors[k] = - y_test * np.log(y_est) - (1 - y_test) * np.log (1 - y_est)\n",
    "        #print(gen_error[kk])\n",
    "        errorANN_inner = 100*(y_est!=y_test).sum().astype(float)/len(y_test) \n",
    "        #print(best_no_neurons)\n",
    "        #print(errorANN_inner)\n",
    "        #print(value)\n",
    "        error_inner_ANN['NO_HIDDEN_of_{0}'.format(best_no_neurons)].append(errorANN_inner) # add errors for each fold to each model\n",
    "        #print(3)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    # Decision tree classifier\n",
    "        for count, value in enumerate(tc):\n",
    "            dist=1\n",
    "            \n",
    "            # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "            dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=value) \n",
    "            dtc.fit(X_train_inner, y_train_inner.ravel());\n",
    "            classifier_lst_dtc.append(dtc)\n",
    "            \n",
    "            y_dtc = dtc.predict(X_test_inner);\n",
    "            errordtc_inner = 100*(y_dtc!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner_dtc['tc_of_{0}'.format(value)].append(errordtc_inner) # add errors for each fold to each model\n",
    "            #print('error_dtc is ' + str(error_inner_dtc))\n",
    "   \n",
    "\n",
    "    # KNN classifier\n",
    "            for count, value in enumerate(K_KNN):\n",
    "                dist=2 # euclidean_distance\n",
    "                       \n",
    "                knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "                knclassifier.fit(X_train_inner, y_train_inner);\n",
    "                classifier_lst_KNN.append(knclassifier)\n",
    "            \n",
    "                y_KNN = knclassifier.predict(X_test_inner);\n",
    "                errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "                #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "                error_inner_KNN['K_KNN_of_{0}'.format(value)].append(errorKNN_inner) # add errors for each fold to each model\n",
    "        \n",
    "        \n",
    "        kk += 1\n",
    "    #dtc\n",
    "    # Find the dtc value with minimum average error value\n",
    "    for key in error_inner_dtc.keys():\n",
    "        index_min_lst_dtc.append(mean(error_inner_dtc[key]))\n",
    "        \n",
    "    print('Inner_error_values_ for dtc are:' + str(index_min_lst_dtc))\n",
    "    index_min_dtc = np.argmin(index_min_lst_dtc) #Find the index of the minimum error value\n",
    "    top_count_dtc = index_min_dtc\n",
    "    min_indices_dtc.append(index_min_dtc) \n",
    "        \n",
    "    index_min_lst_dtc = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_dtc.keys():\n",
    "        error_inner_dtc[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal tc value is: ' + str(top_count_dtc))\n",
    "    \n",
    "    optimal_tc = tc[top_count_dtc]\n",
    "    \n",
    "    print('The optimal tc value across inner CV folds is: ' + str(optimal_tc))\n",
    "    \n",
    "    \n",
    "    dtcclassifierOuter = tree.DecisionTreeClassifier(criterion='gini', max_depth=optimal_tc);  #Uses optimal_tc, which was found in the inner CV loop\n",
    "    dtcclassifierOuter.fit(X_train_outer, y_train_outer.ravel());\n",
    "            \n",
    "    y_dtc_outer = dtcclassifierOuter.predict(X_test_outer);\n",
    "    errordtc_outer = 100*(y_dtc_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_dtc.append(errordtc_outer)\n",
    "    print('Errors for each outer tc fold: ' + str(error_outer_dtc))\n",
    "    \n",
    "   \n",
    "    \n",
    "    # KNN\n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner_KNN.keys():\n",
    "        index_min_lst_KNN.append(mean(error_inner_KNN[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst_KNN))\n",
    "    index_min_KNN = np.argmin(index_min_lst_KNN) #Find the index of the minimum error value\n",
    "    top_count_KNN = index_min_KNN\n",
    "    min_indices_KNN.append(index_min_KNN) \n",
    "        \n",
    "    index_min_lst_KNN = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_KNN.keys():\n",
    "        error_inner_KNN[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count_KNN))\n",
    "    \n",
    "    optimal_K = K_KNN[top_count_KNN]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer_KNN.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer_KNN))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ANN\n",
    "    # Find the KNN value with minimum average error value\n",
    "    for key in error_inner_ANN.keys():\n",
    "        index_min_lst_ANN.append((error_inner_ANN[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst_ANN))\n",
    "    index_min_ANN = np.argmin(index_min_lst_ANN) #Find the index of the minimum error value\n",
    "    top_count_ANN = index_min_ANN\n",
    "    min_indices_ANN.append(index_min_ANN) \n",
    "        \n",
    "    index_min_lst_ANN = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner_ANN.keys():\n",
    "        error_inner_ANN[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal ANN value is: ' + str(top_count_ANN))\n",
    "    \n",
    "    optimal_no_neurons = n_hidden_units[top_count_ANN]\n",
    "    \n",
    "    print('The optimal number of neurons in ANN value across inner CV folds is: ' + str(optimal_no_neurons))\n",
    "    \n",
    "    #knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    #knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    #y_KNN_outer = knclassifierOuter.predict(X_test_outer);\n",
    "    y_est = bestnet[k].sim(X_test).squeeze()\n",
    "    y_est = (y_est>.5).astype(int)\n",
    "    errorANN_outer = 100*(y_est!=y_test).sum().astype(float)/len(y_test)\n",
    "    #error_outer_KNN.append(errorKNN_outer)\n",
    "    error_outer_ANN.append(errorANN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer_ANN))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Fit baseline model\n",
    "            \n",
    "    y_baselinemodel = Baseline_model(y_train_outer, y_test_outer);\n",
    "    error_baseline_outer = 100*(y_baselinemodel!=y_test_outer).sum().astype(float)/len(y_test_outer)  \n",
    "    error_baseline.append(error_baseline_outer)\n",
    "    print('Errors for baseline outer fold'+str(error_baseline))\n",
    "\n",
    "error_dct = error_outer_dtc\n",
    "error_KNN = error_outer_KNN\n",
    "error_ANN = error_outer_ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.0, 25.0, 5.2631578947368425, 15.789473684210526, 21.05263157894737]\n",
      "[20.0, 20.0, 10.526315789473685, 15.789473684210526, 26.31578947368421]\n",
      "[10.526315789473685, 15.789473684210526, 21.05263157894737, 10.526315789473685, 21.05263157894737]\n"
     ]
    }
   ],
   "source": [
    "print(error_dct)\n",
    "print(error_KNN)\n",
    "print(error_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.082474226804123\n",
      "18.144329896907216\n",
      "15.463917525773194\n",
      "21.391752577319586\n"
     ]
    }
   ],
   "source": [
    "# Final generalization error for DCT\n",
    "DTC_error = (len(y_test_outer)/N*np.mat(error_dct)).sum()\n",
    "print(DTC_error)\n",
    "# Final generalization error for KNN\n",
    "KNN_error = (len(y_test_outer)/N*np.mat(error_KNN)).sum()\n",
    "print(KNN_error)\n",
    "# Final generalization error for ANN\n",
    "ANN_error = (len(y_test_outer)/N*np.mat(error_ANN)).sum()\n",
    "print(ANN_error)\n",
    "# Final generalization error for base line model\n",
    "Baseline_error = (len(y_test_outer)/N*np.mat(error_baseline)).sum()\n",
    "print(Baseline_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer error dct is[15.0, 25.0, 5.2631578947368425, 15.789473684210526, 21.05263157894737]\n",
      "Outer error of KNN is[20.0, 20.0, 10.526315789473685, 15.789473684210526, 26.31578947368421]\n",
      "Outer error of ANN is[10.526315789473685, 15.789473684210526, 21.05263157894737, 10.526315789473685, 21.05263157894737]\n",
      "Outer error of baseline_model is[10.0, 15.0, 26.31578947368421, 15.789473684210526, 42.10526315789474]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x287322e3f98>,\n",
       "  <matplotlib.axis.XTick at 0x287322e84e0>,\n",
       "  <matplotlib.axis.XTick at 0x287322ee128>,\n",
       "  <matplotlib.axis.XTick at 0x2873237de80>],\n",
       " <a list of 4 Text xticklabel objects>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28736411e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The two best performing models are from dct and KNN\n",
    "print('Outer error dct is' + str(error_dct))\n",
    "print('Outer error of KNN is' + str(error_KNN))\n",
    "print('Outer error of ANN is' + str(error_ANN))\n",
    "print('Outer error of baseline_model is' + str(error_baseline))\n",
    "\n",
    "figure()\n",
    "boxplot([error_KNN, error_dct, error_ANN, error_baseline])\n",
    "xlabel('Model')\n",
    "ylabel('Cross validation error [%]')\n",
    "xticks([1, 2, 3, 4], ['KNN', 'DTC', 'ANN', 'Baseline'])\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of methods (based on all the different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 and baseline model are not significantly different\n",
      "zb:5.421052631578947\n",
      "sig:6.574524829316712\n",
      "zL:-12.832754649778837\n",
      "zH:23.674859912936725\n",
      "Baseline model and Model 2 are not significantly different\n",
      "zb:3.315789473684211\n",
      "sig:5.332179007121659\n",
      "zL:-11.488712830677182\n",
      "zH:18.1202917780456\n",
      "Model 1 and Model 2 are not significantly different\n",
      "zb:-2.1052631578947363\n",
      "sig:2.0401102571909795\n",
      "zL:-7.769517295536455\n",
      "zH:3.558990979746981\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# The best performing classifiers are KNN and dtc\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = K_outer\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "Error_base_line = np.asarray(error_baseline)\n",
    "Error_model_1 = np.asarray(error_dct)\n",
    "Error_model_2 = np.asarray(error_KNN)\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print('zb:' +str(zb))\n",
    "print('sig:' + str(sig))\n",
    "print('zL:' + str(zL))\n",
    "print('zH:' +str(zH))\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Baseline model and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Baseline model and Model 2 are significantly different.')\n",
    "print('zb:' +str(zb))\n",
    "print('sig:' + str(sig))\n",
    "print('zL:' + str(zL))\n",
    "print('zH:' +str(zH))\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print('zb:' +str(zb))\n",
    "print('sig:' + str(sig))\n",
    "print('zL:' + str(zL))\n",
    "print('zH:' +str(zH))\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gammel kode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of two single models (selected based on error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-7efc38443c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# extract training and test set for current CV fold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# The best performing classifiers are KNN with K = 2 and a dtc with tc=10\n",
    "\n",
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "Error_base_line = np.empty((K,1))\n",
    "Error_model_1 = np.empty((K,1))\n",
    "Error_model_2 = np.empty((K,1))\n",
    "\n",
    "n_tested=0\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K))\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Fit and evaluate KNN\n",
    "    model1 = KNeighborsClassifier(n_neighbors=2, p=dist);\n",
    "    model1 = model1.fit(X_train, y_train)\n",
    "    y_model1 = model1.predict(X_test)\n",
    "    Error_model_1[k] = 100*(y_model1!=y_test).sum().astype(float)/len(y_test)\n",
    "    \n",
    "    # Fit and evaluate Decision Tree classifier\n",
    "    model2 = tree.DecisionTreeClassifier(criterion='gini', max_depth=10);\n",
    "    model2 = model2.fit(X_train, y_train.ravel())\n",
    "    y_model2 = model2.predict(X_test)\n",
    "    Error_model_2[k] = 100*(y_model2!=y_test).sum().astype(float)/len(y_test)  \n",
    "    \n",
    "    # Fit and evaluate baseline model classifier\n",
    "    y_baseline = Baseline_model(y_train, y_test);\n",
    "    Error_base_line[k] = 100*(y_baseline!=y_test).sum().astype(float)/len(y_test)\n",
    "  \n",
    "    k+=1\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Baseline model and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Baseline model and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 and baseline model are significantly different.\n",
      "5.0\n",
      "5.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_parse_args() missing 1 required positional argument: 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3aadf24c2f4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mzL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msig\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mzH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msig\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36mppf\u001b[1;34m(self, q, *args, **kwds)\u001b[0m\n\u001b[0;32m   1898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \"\"\"\n\u001b[1;32m-> 1900\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1901\u001b[0m         \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _parse_args() missing 1 required positional argument: 'df'"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "Error_base_line = min(error_baseline)\n",
    "Error_model_1 = min(error_dct) # Gives the best performing model\n",
    "Error_model_2 = sorted(error_dct)[1] # Gives the second best performing model\n",
    "\n",
    "# Comparison of Baseline model with model 1\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_1)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of Baseline model with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_base_line-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 2 and baseline model are not significantly different')        \n",
    "else:\n",
    "    print('Model 2 and baseline model are significantly different.')\n",
    "print(zL)\n",
    "print(zH)\n",
    "\n",
    "# Comparison of model 1 with model 2\n",
    "\n",
    "# Test if classifiers are significantly different using methods in section 9.3.3\n",
    "# by computing credibility interval. Notice this can also be accomplished by computing the p-value using\n",
    "# [tstatistic, pvalue] = stats.ttest_ind(Error_logreg,Error_dectree)\n",
    "# and test if the p-value is less than alpha=0.05. \n",
    "z = (Error_model_1-Error_model_2)\n",
    "zb = z.mean()\n",
    "nu = K-1\n",
    "sig =  (z-zb).std()  / np.sqrt(K-1)\n",
    "alpha = 0.05\n",
    "\n",
    "zL = zb + sig * stats.t.ppf(alpha/2, nu);\n",
    "zH = zb + sig * stats.t.ppf(1-alpha/2, nu);\n",
    "\n",
    "if zL <= 0 and zH >= 0 :\n",
    "    print('Model 1 and Model 2 are not significantly different')        \n",
    "else:\n",
    "    print('Model 1 and Model 2 are significantly different.')\n",
    "print(zL)\n",
    "print(zH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two level cross validation for KNN - Greta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = [] # List for the errors in outer CV fold\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = [1, 2, 3] # Change here for different nearest neighbour crossvalidation\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True, random_state=seed)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "        counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "        top_count = np.argmax(counts)\n",
    "        # Only use the count from the last iteration! \n",
    "        optimal_K = K_KNN[top_count]\n",
    "        \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=optimal_K, p=dist); #Uses optimal_K, which was found in the inner CV loop\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "errorKNN_inner_GT=[]\n",
    "errorKNN_outer_GT = []\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = []\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K_outer,1))\n",
    "#Error_KNN_inner = np.empty((K_inner,3))\n",
    "#Error_NaïveB = np.empty((K_outer,1))\n",
    "#n_tested=0\n",
    "\n",
    "K_KNN = range(1,41)\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True, random_state=seed)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        \n",
    "        for count, value in enumerate(K_KNN):\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=value, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            errorKNN_inner_GT = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            index_min_lst.append(errorKNN_inner_GT) #Append the error values to a list\n",
    "            \n",
    "        # Find the KNN value with least error value\n",
    "        index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "        min_indices.append(index_min) \n",
    "        \n",
    "        index_min_lst = [] # Clear for next CV fold\n",
    "        \n",
    "        kk += 1\n",
    "\n",
    "    print(min_indices)\n",
    "    counts = np.bincount(min_indices) # Count which index appears the maximum number of times = i.e. the must be the least error value\n",
    "    top_count = np.argmax(counts)\n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    # Only use the count from the last iteration! \n",
    "    optimal_K = K_KNN[top_count]\n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    knclassifierOuter = KNeighborsClassifier(n_neighbors=1, p=dist);\n",
    "    knclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_KNN_outer = knclassifier.predict(X_test_outer);\n",
    "    errorKNN_outer_GT = 100*(y_KNN_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorKNN_outer_GT)\n",
    "    print(error_outer)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "Inner CV-fold 1 of 5\n",
      "[[-1.9993129  -0.72575948 -0.79198919 -1.03002898 -0.86765522 -2.29971238\n",
      "   1.          0.          0.          0.        ]\n",
      " [-1.58702059 -2.20015441  1.36823439 -1.03002898 -0.86765522 -2.29971238\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.5105128  -0.46121762 -0.25193329 -1.03002898 -0.86765522 -1.83463099\n",
      "   1.          0.          0.          0.        ]\n",
      " [-2.04670586 -0.93880639 -1.87210098 -1.03002898 -0.86765522 -1.49161747\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.5226677  -0.3646778   0.01809466  0.35670122 -0.86765522 -1.49161747\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.56020767 -0.20984103 -0.79198919  0.99529051 -0.86765522 -1.4141616\n",
      "   1.          0.          0.          0.        ]\n",
      " [-1.81362657 -0.20984103 -2.2771429  -1.03002898 -0.86765522 -1.24618021\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.9610521  -0.90192675 -0.11691932 -1.03002898 -0.86765522 -1.24618021\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.93418834 -0.05819996  0.15310863 -1.03002898 -0.86765522 -1.05492666\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.12284403 -0.4385849  -0.92700316 -1.03002898 -0.1807427  -0.94018137\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.16302259 -1.33245984  0.2881226  -1.03002898 -0.86765522 -0.89820677\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 0.80038343  0.04790351  0.2881226  -1.03002898  0.39606027 -0.85816274\n",
      "   1.          0.          0.          0.        ]\n",
      " [-1.63076627 -0.84767487 -3.08722674 -1.03002898 -0.86765522 -0.80135103\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.9958673   0.46089542  0.8281785   1.07937567 -0.86765522 -0.76543644\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.17279428 -0.4917387  -0.65697521 -1.03002898 -0.86765522 -0.73094466\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 0.60486894 -0.30009502 -0.52196124  0.95226146  1.09806826 -0.71419787\n",
      "   0.          1.          0.          0.        ]\n",
      " [-1.61593366 -0.59376893 -0.65697521 -0.62277959 -0.86765522 -0.68164068\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.82278841  0.09023368  0.69316453  1.03860789 -0.86765522 -0.65025697\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 0.08264956 -1.18343728  0.55815055  0.13839656 -0.86765522 -0.619965\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.71399732  0.21283185  0.15310863 -1.03002898 -0.44509826 -0.59069151\n",
      "   0.          1.          0.          0.        ]\n",
      " [-1.49290981  0.55616587  0.42313658  1.18900155 -0.86765522 -0.57641572\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.0636628  -1.38806321  0.96319247  0.80827605 -0.86765522 -0.40942861\n",
      "   1.          0.          0.          0.        ]\n",
      " [-1.14287478 -0.84767487 -1.33204508 -1.03002898 -0.86765522 -0.39781765\n",
      "   1.          0.          0.          0.        ]\n",
      " [-1.15993242 -0.96684975 -0.11691932 -1.03002898 -0.44509826 -0.3750503\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.03554419  1.15183144  0.01809466  1.43488428 -0.86765522 -0.34197776\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.76124438 -2.94238594  0.01809466 -1.03002898 -0.86765522 -0.24968869\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.47120382 -1.44501572 -1.06201713  0.5790429   0.01211097 -0.17513581\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.65481608  0.55616587 -0.25193329  1.11787737 -0.1807427  -0.13158654\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 0.35951816  0.62873791 -0.38694727 -1.03002898  0.71191882 -0.09011178\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.1160991  -0.51489465  0.2881226   1.14240568 -0.1807427   0.0377352\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.26772493 -0.55400096 -0.38694727  0.35670122 -0.86765522  0.06527282\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.15936323  0.95303849  0.55815055  1.11787737 -0.1807427   0.07872178\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.11017138 -0.14270309  0.8281785   0.8822505  -0.44509826  0.09851369\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 0.26448829  1.421615    0.01809466  1.36687051 -0.86765522  0.17346783\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.71399732  0.0110004   0.01809466  0.96483055  0.16402005  0.17943223\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.66269388  1.15563954  0.55815055  1.15435171  1.16912805  0.18535613\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.53819093 -0.26497044 -0.65697521 -1.03002898 -0.86765522  0.1970843\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.07083973  1.52790617  0.2881226   1.40088236 -0.86765522  0.2086566\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.75586358  0.31848951 -2.00711495  0.91647239 -0.86765522  0.27503575\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.24626419  0.52151525 -0.38694727  0.82752319 -0.86765522  0.29086898\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.76124438  2.10127925  1.23322042  1.54225202 -0.86765522  0.31663434\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 1.2159132  -0.2441444   1.09820645 -1.03002898  1.24908762  0.32673071\n",
      "   0.          0.          0.          1.        ]\n",
      " [-1.53197866  1.82921036  0.69316453 -1.03002898 -0.86765522  0.42173538\n",
      "   1.          0.          0.          0.        ]\n",
      " [-0.1331195   2.70166094  1.09820645  1.54225202 -0.44509826  0.43068977\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.16203258 -0.67539077  1.77327632  1.14240568 -0.86765522  0.48675094\n",
      "   0.          1.          0.          0.        ]\n",
      " [-0.11521787  0.46089542  0.69316453 -1.03002898  0.28936185  0.50329884\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.40654082  0.51652225  0.69316453 -1.03002898  1.50170584  0.69391731\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.56363872  1.88843646  1.09820645  1.40088236  0.48894996  0.79630031\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.01288993  1.70306453  1.90829029  1.54225202 -0.86765522  0.83354436\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.10052143 -1.31058265  0.2881226   0.31819952  0.28936185  0.90356948\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.99242046 -0.3646778  -0.92700316  0.23411435  1.80201365  0.91641341\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.077152    0.60960358  1.77327632 -0.43510323  0.5312501   0.94648734\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.132233    0.49140008  0.15310863  0.7030969   1.38643629  0.95140024\n",
      "   0.          0.          0.          1.        ]\n",
      " [ 0.18109221  0.1899692  -0.52196124  1.10527971  0.71191882  0.96597463\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.66548696 -0.25800887  0.01809466 -1.03002898  1.80201365  1.00368795\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 0.18109221  0.15525053  1.63826234  0.5790429   0.71191882  1.31945687\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.61742159  1.10952004  0.55815055 -1.03002898 -0.86765522  1.3509826\n",
      "   1.          0.          0.          0.        ]\n",
      " [ 1.26244405  0.58060761  0.55815055 -1.03002898  1.07914887  1.66041493\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 2.10739693  0.62873791 -2.68218482 -1.03002898  1.68826718  1.92104373\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.30704467  0.34014146  0.55815055  1.0100326   1.24908762  2.61164875\n",
      "   0.          1.          0.          0.        ]\n",
      " [ 1.80971922  0.81196061  0.55815055  0.23411435  2.21673517  2.70345173\n",
      "   0.          1.          0.          0.        ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-af75c218e0c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mnbclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest_prior\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mnbclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mclassifier_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    602\u001b[0m         self.feature_count_ = np.zeros((n_effective_classes, n_features),\n\u001b[0;32m    603\u001b[0m                                        dtype=np.float64)\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X must be non-negative"
     ]
    }
   ],
   "source": [
    "### OBS. method can not use X values < 0\n",
    "\n",
    "## Crossvalidation for Naive Bayes\n",
    "## The selection of optimal model is based on an average of the inner errors for each model\n",
    "\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True, random_state=seed)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "index_min_lst = []\n",
    "min_indices = []\n",
    "error_outer = np.empty((1,1)) # List for the errors in outer CV fold\n",
    "dict_inner = {}\n",
    "error_inner = {} # Dict with the errors in the innter CV fold for each tested model\n",
    "\n",
    "# Naive Bayes classifier parameters\n",
    "alpha = [1]         # additive parameter (e.g. Laplace correction), lægges til da log bliver taget i MultinormilNB\n",
    "\n",
    "for count, value in enumerate(K_KNN):\n",
    "    error_inner['K_KNN_of_{0}'.format(value)] = []\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    k += 1\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('Inner CV-fold {0} of {1}'.format(kk+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "#         print(len(X_train_inner))\n",
    "#         print(len(y_train_inner))\n",
    "        print(X_train_inner) \n",
    "        for count, value in enumerate(alpha):\n",
    "            est_prior = True  # uniform prior (change to True to estimate prior from data)    \n",
    "                       \n",
    "            nbclassifier = MultinomialNB(alpha=alpha, fit_prior=est_prior);\n",
    "            nbclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(nbclassifier)\n",
    " \n",
    "            y_NB = nbclassifier.predict(X_test_inner);\n",
    "            errorNB_inner = 100*(y_NB!=y_test_inner).sum().astype(float)/len(y_test_inner)  \n",
    "            #index_min_lst.append(errorKNN_inner) #Append the error values to a list\n",
    "            error_inner['alpha_of_{0}'.format(value)].append(errorNB_inner) # add errors for each fold to each model\n",
    "            \n",
    "        kk += 1\n",
    "        \n",
    "    # Find the alpha value with minimum average error value\n",
    "    for key in error_inner.keys():\n",
    "        index_min_lst.append(mean(error_inner[key]))\n",
    "        \n",
    "    print('Inner_error_values are:' + str(index_min_lst))\n",
    "    index_min = np.argmin(index_min_lst) #Find the index of the minimum error value\n",
    "    top_count = index_min\n",
    "    min_indices.append(index_min) \n",
    "        \n",
    "    index_min_lst = [] # Clear for next CV fold\n",
    "    \n",
    "    for key in error_inner.keys():\n",
    "        error_inner[key] = [] # Clear for next CV fold\n",
    "        \n",
    "      \n",
    "    print('The index of optimal KNN value is: ' + str(top_count))\n",
    "    \n",
    "    optimal_alpha = alpha[top_count]\n",
    "    \n",
    "    print('The optimal KNN value across inner CV folds is: ' + str(optimal_K))\n",
    "    \n",
    "    nbclassifierOuter = MultinomialNB(alpha=optimal_alpha, fit_prior=est_prior); #Uses optimal_alpha, which was found in the inner CV loop\n",
    "    nbclassifierOuter.fit(X_train_outer, y_train_outer);\n",
    "            \n",
    "    y_NB_outer = nbclassifier.predict(X_test_outer);\n",
    "    errorNB_outer = 100*(y_NB_outer!=y_test_outer).sum().astype(float)/len(y_test_outer)\n",
    "    error_outer.append(errorNB_outer)\n",
    "    print('Errors for each outer CV fold: ' + str(error_outer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

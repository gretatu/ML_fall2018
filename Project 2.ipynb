{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The purpose of this application is to solve relevant classification and regression problems for the prostate dataset for use in the project in 02450 Intro to Machine Learning\n",
    "\n",
    "Author: Naia Wright\n",
    "\n",
    "Reviewed by:  \n",
    "\n",
    "Last modified: 28/10/18, 09:39\n",
    "\n",
    "#### Change-log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from scipy.linalg import svd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.linear_model as lm\n",
    "from matplotlib.pylab import figure, plot, xlabel, ylabel, legend, ylim, show\n",
    "\n",
    "from matplotlib.pyplot import figure, boxplot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection, tree\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib.pyplot import figure, plot, subplot, title, xlabel, ylabel, show, clim\n",
    "from scipy.io import loadmat\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn import model_selection\n",
    "from toolbox_02450 import feature_selector_lr, bmplot\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a method for importing a spread_sheet using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(path, sheet):\n",
    "    \"\"\"\n",
    "    Method for importing data from a spreadsheet.\n",
    "\n",
    "    :param path: full path to the spreadsheet to load\n",
    "    :param sheet: name of the sheet in the workbook that is loaded\n",
    "    :return: pandas dataFrame with imported data\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    out = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path and sheet name in the prostate workbook\n",
    "#filePath = 'C:/Users/PeterBakke/Documents/git/ML_fall2018/Data/Prostate.xlsx'\n",
    "filePath = 'C:/Users/Greta/Documents/Github/ML_fall2018/Data/Prostate.xlsx'\n",
    "#filePath = 'C:/Users/narisa/Documents/GitHub/ML_fall2018/Data/Prostate.xlsx'\n",
    "sheet = 'Sheet1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prostate data into dataFrame\n",
    "myData = DataLoader(path=filePath, sheet=sheet)\n",
    "\n",
    "# delete irrelevant columns\n",
    "del myData['ID']\n",
    "del myData['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lCaVol', 'lWeight', 'Age', 'lBPH', 'SVI', 'lCP', 'Gleason', 'pgg45', 'lPSA']\n",
      "{6: 0, 7: 1, 8: 2, 9: 3}\n"
     ]
    }
   ],
   "source": [
    "# extract class names and encode with integers (dict)\n",
    "\n",
    "classLabels = myData['Gleason'].values.tolist()\n",
    "classNames = sorted(set(classLabels))\n",
    "classDict = dict(zip(classNames, range(4)))\n",
    "\n",
    "#del myData['Gleason']\n",
    "\n",
    "attributeNames = list(myData.columns.values)\n",
    "\n",
    "print(attributeNames)\n",
    "print(classDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract vector y, convert to NumPy array\n",
    "y = np.asarray([classDict[value] for value in classLabels])\n",
    "\n",
    "# Convert dataFrame to numpy array\n",
    "X = myData.values\n",
    "\n",
    "# Compute values of N, M and C\n",
    "N = len(y)\n",
    "M = len(attributeNames)\n",
    "C = len(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data with mean and std\n",
    "Y = (X - np.ones((N,1))*X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.79818495e-01  2.76945900e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -4.30782900e-01]\n",
      " [-9.94252273e-01  3.31962600e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [-5.10825624e-01  2.69124300e+00  7.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "  -1.62518900e-01]\n",
      " [-1.20397280e+00  3.28278900e+00  5.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "  -1.62518900e-01]\n",
      " [ 7.51416089e-01  3.43237300e+00  6.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.71563600e-01]\n",
      " [-1.04982212e+00  3.22882600e+00  5.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 7.37164066e-01  3.47351800e+00  6.40000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   7.65467800e-01]\n",
      " [ 6.93147181e-01  3.53950900e+00  5.80000000e+01  1.53686722e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   8.54415300e-01]\n",
      " [-7.76528789e-01  3.53950900e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.23143551e-01  3.24454400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.04731900e+00]\n",
      " [ 2.54642218e-01  3.60413800e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [-1.34707365e+00  3.59868100e+00  6.30000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.26694760e+00]\n",
      " [ 1.61342993e+00  3.02286100e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.26694760e+00]\n",
      " [ 1.47704872e+00  2.99822900e+00  6.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   1.34807310e+00]\n",
      " [ 1.20597081e+00  3.44201900e+00  5.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  5.00000000e+00\n",
      "   1.39871690e+00]\n",
      " [ 1.54115907e+00  3.06105200e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.44691900e+00]\n",
      " [-4.15515444e-01  3.51601300e+00  7.00000000e+01  1.24415459e+00\n",
      "   0.00000000e+00 -5.97837000e-01  7.00000000e+00  3.00000000e+01\n",
      "   1.47017580e+00]\n",
      " [ 2.28848617e+00  3.64935900e+00  6.60000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.49290410e+00]\n",
      " [-5.62118918e-01  3.26766600e+00  4.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.55814460e+00]\n",
      " [ 1.82321557e-01  3.82537500e+00  7.00000000e+01  1.65822808e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.59938760e+00]\n",
      " [ 1.14740245e+00  3.41936500e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.63899670e+00]\n",
      " [ 2.05923883e+00  3.50104300e+00  6.00000000e+01  1.47476301e+00\n",
      "   0.00000000e+00  1.34807315e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.65822810e+00]\n",
      " [-5.44727175e-01  3.37588000e+00  5.90000000e+01 -7.98507700e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.69561560e+00]\n",
      " [ 1.78170913e+00  3.45157400e+00  6.30000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  1.17865500e+00  7.00000000e+00  6.00000000e+01\n",
      "   1.71379790e+00]\n",
      " [ 3.85262401e-01  3.66740000e+00  6.90000000e+01  1.59938758e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.73165550e+00]\n",
      " [ 1.44691898e+00  3.12456500e+00  6.80000000e+01  3.00104590e-01\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.76644170e+00]\n",
      " [ 5.12823626e-01  3.71965100e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  7.00000000e+01\n",
      "   1.80005830e+00]\n",
      " [-4.00477567e-01  3.86597900e+00  6.70000000e+01  1.81645208e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   1.81645210e+00]\n",
      " [ 1.04027671e+00  3.12895100e+00  6.70000000e+01  2.23143550e-01\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  8.00000000e+01\n",
      "   1.84845480e+00]\n",
      " [ 2.40964417e+00  3.37588000e+00  6.50000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.61938824e+00  6.00000000e+00  0.00000000e+00\n",
      "   1.89461690e+00]\n",
      " [ 2.85178942e-01  4.09016900e+00  6.50000000e+01  1.96290773e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   1.92424870e+00]\n",
      " [ 1.82321557e-01  3.80443800e+00  6.50000000e+01  1.70474809e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 1.27536280e+00  3.03735400e+00  7.10000000e+01  1.26694760e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.00821400e+00]\n",
      " [ 9.95033100e-03  3.26766600e+00  5.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.02154760e+00]\n",
      " [-1.00503360e-02  3.21687400e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.04769280e+00]\n",
      " [ 1.30833282e+00  4.11985000e+00  6.40000000e+01  2.17133681e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.08567210e+00]\n",
      " [ 1.42310833e+00  3.65713100e+00  7.30000000e+01 -5.79818500e-01\n",
      "   0.00000000e+00  1.65822808e+00  8.00000000e+00  1.50000000e+01\n",
      "   2.15755930e+00]\n",
      " [ 4.57424847e-01  2.37490600e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.19165350e+00]\n",
      " [ 2.66095859e+00  4.08513600e+00  6.80000000e+01  1.37371558e+00\n",
      "   1.00000000e+00  1.83258146e+00  7.00000000e+00  3.50000000e+01\n",
      "   2.21375390e+00]\n",
      " [ 7.97507196e-01  3.01308100e+00  5.60000000e+01  9.36093360e-01\n",
      "   0.00000000e+00 -1.62518930e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.27726730e+00]\n",
      " [ 6.20576488e-01  3.14199500e+00  6.00000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  9.00000000e+00  8.00000000e+01\n",
      "   2.29757260e+00]\n",
      " [ 1.44220199e+00  3.68261000e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   2.30757260e+00]\n",
      " [ 5.82215620e-01  3.86597900e+00  6.20000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.32727770e+00]\n",
      " [ 1.77155676e+00  3.89690900e+00  6.10000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  6.00000000e+00\n",
      "   2.37490580e+00]\n",
      " [ 1.48613970e+00  3.40949600e+00  6.60000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.52172060e+00]\n",
      " [ 1.66392610e+00  3.39282900e+00  6.10000000e+01  6.15185640e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.55334380e+00]\n",
      " [ 2.72785283e+00  3.99544500e+00  7.90000000e+01  1.87946505e+00\n",
      "   1.00000000e+00  2.65675691e+00  9.00000000e+00  1.00000000e+02\n",
      "   2.56878810e+00]\n",
      " [ 1.16315081e+00  4.03512500e+00  6.80000000e+01  1.71379793e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  4.00000000e+01\n",
      "   2.56878810e+00]\n",
      " [ 1.74571553e+00  3.49802200e+00  4.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.22082992e+00  3.56812300e+00  7.00000000e+01  1.37371558e+00\n",
      "   0.00000000e+00 -7.98507700e-01  6.00000000e+00  0.00000000e+00\n",
      "   2.59151640e+00]\n",
      " [ 1.09192330e+00  3.99360300e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+01\n",
      "   2.65675690e+00]\n",
      " [ 1.66013103e+00  4.23483100e+00  6.40000000e+01  2.07317193e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.67759100e+00]\n",
      " [ 5.12823626e-01  3.63363100e+00  6.40000000e+01  1.49290410e+00\n",
      "   0.00000000e+00  4.87901600e-02  7.00000000e+00  7.00000000e+01\n",
      "   2.68444030e+00]\n",
      " [ 2.12704052e+00  4.12147300e+00  6.80000000e+01  1.76644166e+00\n",
      "   0.00000000e+00  1.44691898e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.69124310e+00]\n",
      " [ 3.15359036e+00  3.51601300e+00  5.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  5.00000000e+00\n",
      "   2.70471130e+00]\n",
      " [ 1.26694760e+00  4.28013200e+00  6.60000000e+01  2.12226154e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   2.71800050e+00]\n",
      " [ 9.74559640e-01  2.86505400e+00  4.70000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  4.00000000e+00\n",
      "   2.78809290e+00]\n",
      " [ 4.63734016e-01  3.76468200e+00  4.90000000e+01  1.42310833e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.79422790e+00]\n",
      " [ 5.42324291e-01  4.17822600e+00  7.00000000e+01  4.38254930e-01\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.00000000e+01\n",
      "   2.80638610e+00]\n",
      " [ 1.06125650e+00  3.85121100e+00  6.10000000e+01  1.29472717e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.81241020e+00]\n",
      " [ 4.57424847e-01  4.52450200e+00  7.30000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.84199820e+00]\n",
      " [ 1.99741771e+00  3.71965100e+00  6.30000000e+01  1.61938824e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  4.00000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.77570885e+00  3.52488900e+00  7.20000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  1.55814462e+00  9.00000000e+00  9.50000000e+01\n",
      "   2.85359250e+00]\n",
      " [ 2.03470565e+00  3.91701100e+00  6.60000000e+01  2.00821403e+00\n",
      "   1.00000000e+00  2.11021320e+00  7.00000000e+00  6.00000000e+01\n",
      "   2.88200350e+00]\n",
      " [ 2.07317193e+00  3.62300700e+00  6.40000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.88200350e+00]\n",
      " [ 1.45861502e+00  3.83622100e+00  6.10000000e+01  1.32175584e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  2.00000000e+01\n",
      "   2.88759010e+00]\n",
      " [ 2.02287119e+00  3.87846600e+00  6.80000000e+01  1.78339122e+00\n",
      "   0.00000000e+00  1.32175584e+00  7.00000000e+00  7.00000000e+01\n",
      "   2.92046980e+00]\n",
      " [ 2.19833507e+00  4.05091500e+00  7.20000000e+01  2.30757263e+00\n",
      "   0.00000000e+00 -4.30782920e-01  7.00000000e+00  1.00000000e+01\n",
      "   2.96269240e+00]\n",
      " [-4.46287103e-01  4.40854700e+00  6.90000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   2.96269240e+00]\n",
      " [ 1.19392247e+00  4.78038300e+00  7.20000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -7.98507700e-01  7.00000000e+00  5.00000000e+00\n",
      "   2.97297530e+00]\n",
      " [ 1.86408013e+00  3.59319400e+00  6.00000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.01308090e+00]\n",
      " [ 1.16002092e+00  3.34109300e+00  7.70000000e+01  1.74919985e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  2.50000000e+01\n",
      "   3.03735390e+00]\n",
      " [ 1.21491274e+00  3.82537500e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.23143550e-01  7.00000000e+00  2.00000000e+01\n",
      "   3.05635690e+00]\n",
      " [ 1.83896107e+00  3.23671600e+00  6.00000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  1.17865500e+00  9.00000000e+00  9.00000000e+01\n",
      "   3.07500550e+00]\n",
      " [ 2.99922616e+00  3.84908300e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.90954250e+00  7.00000000e+00  2.00000000e+01\n",
      "   3.27525620e+00]\n",
      " [ 3.14113048e+00  3.26384900e+00  6.80000000e+01 -5.12932900e-02\n",
      "   1.00000000e+00  2.42036813e+00  7.00000000e+00  5.00000000e+01\n",
      "   3.33754740e+00]\n",
      " [ 2.01089500e+00  4.43378900e+00  7.20000000e+01  2.12226154e+00\n",
      "   0.00000000e+00  5.00775290e-01  7.00000000e+00  6.00000000e+01\n",
      "   3.39282910e+00]\n",
      " [ 2.53765721e+00  4.35478400e+00  7.80000000e+01  2.32630162e+00\n",
      "   0.00000000e+00 -1.38629436e+00  7.00000000e+00  1.00000000e+01\n",
      "   3.43559880e+00]\n",
      " [ 2.64830020e+00  3.58212900e+00  6.90000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.58399755e+00  7.00000000e+00  7.00000000e+01\n",
      "   3.45789270e+00]\n",
      " [ 2.77944020e+00  3.82319200e+00  6.30000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00  3.71563560e-01  7.00000000e+00  5.00000000e+01\n",
      "   3.51303690e+00]\n",
      " [ 1.46787435e+00  3.07037600e+00  6.60000000e+01  5.59615790e-01\n",
      "   0.00000000e+00  2.23143550e-01  7.00000000e+00  4.00000000e+01\n",
      "   3.51601310e+00]\n",
      " [ 2.51365606e+00  3.47351800e+00  5.70000000e+01  4.38254930e-01\n",
      "   0.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.53076260e+00]\n",
      " [ 2.61300665e+00  3.88875400e+00  7.70000000e+01 -5.27632740e-01\n",
      "   1.00000000e+00  5.59615790e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.56529840e+00]\n",
      " [ 2.67759099e+00  3.83837600e+00  6.50000000e+01  1.11514159e+00\n",
      "   0.00000000e+00  1.74919985e+00  9.00000000e+00  7.00000000e+01\n",
      "   3.57094020e+00]\n",
      " [ 1.56234630e+00  3.70990700e+00  6.00000000e+01  1.69561561e+00\n",
      "   0.00000000e+00  8.10930220e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.58767690e+00]\n",
      " [ 3.30284926e+00  3.51898000e+00  6.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.32727771e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.63098550e+00]\n",
      " [ 2.02419307e+00  3.73169900e+00  5.80000000e+01  1.63899671e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   3.68009090e+00]\n",
      " [ 1.73165554e+00  3.36901800e+00  6.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  3.00104590e-01  7.00000000e+00  3.00000000e+01\n",
      "   3.71235180e+00]\n",
      " [ 2.80759383e+00  4.71805200e+00  6.50000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  6.00000000e+01\n",
      "   3.98434370e+00]\n",
      " [ 1.56234630e+00  3.69511000e+00  7.60000000e+01  9.36093360e-01\n",
      "   1.00000000e+00  8.10930220e-01  7.00000000e+00  7.50000000e+01\n",
      "   3.99360300e+00]\n",
      " [ 3.24649099e+00  4.10181700e+00  6.80000000e+01 -1.38629436e+00\n",
      "   0.00000000e+00 -1.38629436e+00  6.00000000e+00  0.00000000e+00\n",
      "   4.02980600e+00]\n",
      " [ 2.53290285e+00  3.67756600e+00  6.10000000e+01  1.34807315e+00\n",
      "   1.00000000e+00 -1.38629436e+00  7.00000000e+00  1.50000000e+01\n",
      "   4.12955080e+00]\n",
      " [ 2.83026783e+00  3.87639600e+00  6.80000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  1.32175584e+00  7.00000000e+00  6.00000000e+01\n",
      "   4.38514680e+00]\n",
      " [ 3.82100361e+00  3.89690900e+00  4.40000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.16905370e+00  7.00000000e+00  4.00000000e+01\n",
      "   4.68444340e+00]\n",
      " [ 2.90744736e+00  3.39618500e+00  5.20000000e+01 -1.38629436e+00\n",
      "   1.00000000e+00  2.46385324e+00  7.00000000e+00  1.00000000e+01\n",
      "   5.14312450e+00]\n",
      " [ 2.88256357e+00  3.77391000e+00  6.80000000e+01  1.55814462e+00\n",
      "   1.00000000e+00  1.55814462e+00  7.00000000e+00  8.00000000e+01\n",
      "   5.47750900e+00]\n",
      " [ 3.47196645e+00  3.97499800e+00  6.80000000e+01  4.38254930e-01\n",
      "   1.00000000e+00  2.90416508e+00  7.00000000e+00  2.00000000e+01\n",
      "   5.58293220e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Remove attribute 5 (SVI) from X\n",
    "X_classification = X[:,[0,1,2,3,5,6,7,8]]\n",
    "print(X)\n",
    "# Use attribute 5 (SVI) as y\n",
    "y_classification = X[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_est_white_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-64703e7f17cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mclass0_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass0_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est_white_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass0_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mclass1_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass1_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_est_white_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass1_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_est_white_prob' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit logistic regression model\n",
    "model = lm.logistic.LogisticRegression()\n",
    "model = model.fit(X_classification,y_classification)\n",
    "\n",
    "# Classify observation according to SVI (0/1) and assess probabilities\n",
    "y_est = model.predict(X_classification)\n",
    "y_est_no_SVI_prob = model.predict_proba(X_classification)[:, 0] \n",
    "\n",
    "# Define a new data object (new type of wine), as in exercise 5.1.7\n",
    "#x = np.array([6.9, 1.09, .06, 2.1, .0061, 12, 31, .99, 3.5, .44, 12]).reshape(1,-1)\n",
    "# Evaluate the probability of x being a white wine (class=0) \n",
    "#x_class = model.predict_proba(x)[0,0]\n",
    "\n",
    "# Evaluate classifier's misclassification rate over entire training data\n",
    "misclass_rate = sum(np.abs(y_est - y_classification)) / float(len(y_est))\n",
    "\n",
    "# Display classification results\n",
    "#print('\\nProbability of given sample not having a white wine: {0:.4f}'.format(x_class))\n",
    "#print('\\nOverall misclassification rate: {0:.3f}'.format(misclass_rate))\n",
    "\n",
    "f = figure();\n",
    "class0_ids = np.nonzero(y==0)[0].tolist()\n",
    "plot(class0_ids, y_est_white_prob[class0_ids], '.y')\n",
    "class1_ids = np.nonzero(y==1)[0].tolist()\n",
    "plot(class1_ids, y_est_white_prob[class1_ids], '.r')\n",
    "xlabel('Data object (men)'); ylabel('Predicted prob. of no seminal vesicle invation');\n",
    "legend(['No seminal vesicle invasion', 'Seminal vesicle incation'])\n",
    "ylim(-0.01,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two level cross validation for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 5\n",
      "CV-fold 1 of 5\n",
      "61\n",
      "61\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-804fecca19b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mknclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK_KNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mknclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_inner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_inner\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mclassifier_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\workspace-gpu\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\workspace-gpu\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;31m# and KDTree is generally faster when available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             if ((self.n_neighbors is None or\n\u001b[1;32m--> 229\u001b[1;33m                  self.n_neighbors < self._fit_X.shape[0] // 2) and\n\u001b[0m\u001b[0;32m    230\u001b[0m                     self.metric != 'precomputed'):\n\u001b[0;32m    231\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mVALID_METRICS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 5\n",
    "K_inner = 5\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "Error_logreg = np.empty((K_outer,1))\n",
    "Error_KNN_inner = np.empty((K_inner,3))\n",
    "Error_NaïveB = np.empty((K_outer,1))\n",
    "n_tested=0\n",
    "\n",
    "K_KNN = [1, 10, 20]\n",
    "\n",
    "k=0\n",
    "classifier_lst = []\n",
    "\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    "    \n",
    "    CV_inner = model_selection.KFold(n_splits=K_inner,shuffle=True)\n",
    "    \n",
    "    kk=0\n",
    "    for train_inner_index, test_inner_index in CV_inner.split(X_train_outer,y_train_outer):\n",
    "        print('CV-fold {0} of {1}'.format(k+1,K_inner))\n",
    "\n",
    "        # extract training and test set for current CV fold\n",
    "        X_train_inner = X_train_outer[train_inner_index,:]\n",
    "        y_train_inner = y_train_outer[train_inner_index]\n",
    "        X_test_inner = X_train_outer[test_inner_index,:]\n",
    "        y_test_inner = y_train_outer[test_inner_index]\n",
    "        \n",
    "        print(len(X_train_inner))\n",
    "        print(len(y_train_inner))\n",
    "        \n",
    "        for i, KNN in enumerate(K_KNN):\n",
    "        \n",
    "            # Distance metric (corresponds to 2nd norm, euclidean distance).\n",
    "            # You can set dist=1 to obtain manhattan distance (cityblock distance).\n",
    "            dist=1\n",
    "    \n",
    "            knclassifier = KNeighborsClassifier(n_neighbors=K_KNN, p=dist);\n",
    "            knclassifier.fit(X_train_inner, y_train_inner);\n",
    "            classifier_lst.append(knclassifier)\n",
    "            \n",
    "            y_KNN = knclassifier.predict(X_test_inner);\n",
    "            Error_KNN_inner[kk] = 100*(y_KNN!=y_test_inner).sum().astype(float)/len(y_test_inner)\n",
    "            kk+=1\n",
    "            \n",
    "            \n",
    "            # Take model out here with optimal K\n",
    "        # Test min error \n",
    "        index_min = np.argmin(Error_KNN_inner)\n",
    "        \n",
    "        print('Inner error is (with index)')\n",
    "        print(Error_KNN_inner)\n",
    "        print(index_min)\n",
    "    # Test here\n",
    "    \n",
    "    optimal_model = classifier_lst[index_min]\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complexity parameters\n",
    "K_KNN = [1, 5, 10]\n",
    "\n",
    "# K-fold crossvalidation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True)\n",
    "\n",
    "# Initialize variable\n",
    "Error_train = np.empty((len(K_KNN),K))\n",
    "Error_test = np.empty((len(K_KNN),K))\n",
    "\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    print('Computing CV fold: {0}/{1}..'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train, y_train = X[train_index,:], y[train_index]\n",
    "    X_test, y_test = X[test_index,:], y[test_index]\n",
    "\n",
    "    for i, t in enumerate(tc):\n",
    "        # Fit decision tree classifier, Gini split criterion, different pruning levels\n",
    "        dtc = tree.DecisionTreeClassifier(criterion='gini', max_depth=t)\n",
    "        dtc = dtc.fit(X_train,y_train.ravel())\n",
    "        y_est_test = dtc.predict(X_test)\n",
    "        y_est_train = dtc.predict(X_train)\n",
    "        # Evaluate misclassification rate over train/test data (in this CV fold)\n",
    "        misclass_rate_test = sum(np.abs(y_est_test - y_test)) / float(len(y_est_test))\n",
    "        misclass_rate_train = sum(np.abs(y_est_train - y_train)) / float(len(y_est_train))\n",
    "        Error_test[i,k], Error_train[i,k] = misclass_rate_test, misclass_rate_train\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-fold 1 of 2\n",
      "[0.75  0.625]\n",
      "CV-fold 2 of 2\n",
      "[0.8        0.83333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score \n",
    "## Crossvalidation for KNN\n",
    "# Create crossvalidation partition for evaluation\n",
    "K_outer = 2\n",
    "CV_outer = model_selection.KFold(n_splits=K_outer,shuffle=True)\n",
    "#CV = model_selection.StratifiedKFold(n_splits=K)\n",
    "\n",
    "# Initialize variables\n",
    "#Error_logreg = np.empty((K,1))\n",
    "#Error_KNN_inner = np.empty((K,1))\n",
    "#Error_NaïveB = np.empty((K,1))\n",
    "#n_tested=0\n",
    "\n",
    "\n",
    "\n",
    "k=0\n",
    "for train_outer_index, test_outer_index in CV_outer.split(X_classification,y_classification):\n",
    "    print('CV-fold {0} of {1}'.format(k+1,K_outer))\n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train_outer = X_classification[train_outer_index,:]\n",
    "    y_train_outer = y_classification[train_outer_index]\n",
    "    X_test_outer = X_classification[test_outer_index,:]\n",
    "    y_test_outer = y_classification[test_outer_index]\n",
    " \n",
    "    # Distance metric (corresponds to 2nd norm, euclidean distance).\n",
    "    # You can set dist=1 to obtain manhattan distance (cityblock distance).\n",
    "    dist= 2\n",
    "    cv_scores = []\n",
    "    for K_KNN in [1, 5, 10]:\n",
    "        knclassifier = KNeighborsClassifier(n_neighbors=K_KNN, p=dist); \n",
    "        #cv_results = cross_validate(knclassifier, X_train_outer, y_train_outer, cv=2, return_train_score=False)\n",
    "        #print(sorted(cv_results.keys()))\n",
    "        #print(cv_results['test_score'])\n",
    "        scores = cross_val_score(knclassifier, X_train_outer, y_train_outer, cv=2, scoring='accuracy')\n",
    "        #cv_scores.append(scores.mean())\n",
    "    print(scores)\n",
    "    k+=1\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cross_val_score in module sklearn.model_selection._validation:\n",
      "\n",
      "cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
      "    Evaluate a score by cross-validation\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    estimator : estimator object implementing 'fit'\n",
      "        The object to use to fit the data.\n",
      "    \n",
      "    X : array-like\n",
      "        The data to fit. Can be for example a list, or an array.\n",
      "    \n",
      "    y : array-like, optional, default: None\n",
      "        The target variable to try to predict in the case of\n",
      "        supervised learning.\n",
      "    \n",
      "    groups : array-like, with shape (n_samples,), optional\n",
      "        Group labels for the samples used while splitting the dataset into\n",
      "        train/test set.\n",
      "    \n",
      "    scoring : string, callable or None, optional, default: None\n",
      "        A string (see model evaluation documentation) or\n",
      "        a scorer callable object / function with signature\n",
      "        ``scorer(estimator, X, y)``.\n",
      "    \n",
      "    cv : int, cross-validation generator or an iterable, optional\n",
      "        Determines the cross-validation splitting strategy.\n",
      "        Possible inputs for cv are:\n",
      "    \n",
      "        - None, to use the default 3-fold cross validation,\n",
      "        - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "        - An object to be used as a cross-validation generator.\n",
      "        - An iterable yielding train, test splits.\n",
      "    \n",
      "        For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "        other cases, :class:`KFold` is used.\n",
      "    \n",
      "        Refer :ref:`User Guide <cross_validation>` for the various\n",
      "        cross-validation strategies that can be used here.\n",
      "    \n",
      "    n_jobs : integer, optional\n",
      "        The number of CPUs to use to do the computation. -1 means\n",
      "        'all CPUs'.\n",
      "    \n",
      "    verbose : integer, optional\n",
      "        The verbosity level.\n",
      "    \n",
      "    fit_params : dict, optional\n",
      "        Parameters to pass to the fit method of the estimator.\n",
      "    \n",
      "    pre_dispatch : int, or string, optional\n",
      "        Controls the number of jobs that get dispatched during parallel\n",
      "        execution. Reducing this number can be useful to avoid an\n",
      "        explosion of memory consumption when more jobs get dispatched\n",
      "        than CPUs can process. This parameter can be:\n",
      "    \n",
      "            - None, in which case all the jobs are immediately\n",
      "              created and spawned. Use this for lightweight and\n",
      "              fast-running jobs, to avoid delays due to on-demand\n",
      "              spawning of the jobs\n",
      "    \n",
      "            - An int, giving the exact number of total jobs that are\n",
      "              spawned\n",
      "    \n",
      "            - A string, giving an expression as a function of n_jobs,\n",
      "              as in '2*n_jobs'\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    scores : array of float, shape=(len(list(cv)),)\n",
      "        Array of scores of the estimator for each run of the cross validation.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn import datasets, linear_model\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> diabetes = datasets.load_diabetes()\n",
      "    >>> X = diabetes.data[:150]\n",
      "    >>> y = diabetes.target[:150]\n",
      "    >>> lasso = linear_model.Lasso()\n",
      "    >>> print(cross_val_score(lasso, X, y))  # doctest: +ELLIPSIS\n",
      "    [ 0.33150734  0.08022311  0.03531764]\n",
      "    \n",
      "    See Also\n",
      "    ---------\n",
      "    :func:`sklearn.model_selection.cross_validate`:\n",
      "        To run cross-validation on multiple metrics and also to return\n",
      "        train scores, fit times and score times.\n",
      "    \n",
      "    :func:`sklearn.metrics.make_scorer`:\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
